{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 2: Multiple Regression (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first notebook we explored multiple regression using graphlab create. Now we will use graphlab along with numpy to solve for the regression weights with gradient descent.\n",
    "\n",
    "In this notebook we will cover estimating multiple regression weights via gradient descent. You will:\n",
    "* Add a constant column of 1's to a graphlab SFrame to account for the intercept\n",
    "* Convert an SFrame into a Numpy array\n",
    "* Write a predict_output() function using Numpy\n",
    "* Write a numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size and tolerance.\n",
    "* Use the gradient descent function to estimate regression weights for multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of graphlab (>= 1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to dxiao@bloomu.edu and will expire on April 02, 2020.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\danqi\\AppData\\Local\\Temp\\graphlab_server_1558116059.log.0\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do any \"feature engineering\" like creating new features or adjusting existing ones we should do this directly using the SFrames as seen in the other Week 2 notebook. For this notebook, however, we will work with the existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although SFrames offer a number of benefits to users (especially when using Big Data and built-in graphlab functions) in order to understand the details of the implementation of algorithms it's important to work with a library that allows for direct (and optimized) matrix operations. Numpy is a Python solution to work with matrices (or any multi-dimensional \"array\").\n",
    "\n",
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for *all* the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\". \n",
    "\n",
    "First we need to take the SFrame of our data and convert it into a 2D numpy array (also called a matrix). To do this we use graphlab's built in .to_dataframe() which converts the SFrame into a Pandas (another python library) dataframe. We can then use Panda's .as_matrix() to convert the dataframe into a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that will accept an SFrame, a list of feature names (e.g. ['sqft_living', 'bedrooms']) and an target feature e.g. ('price') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "* A numpy array containing the values of the output\n",
    "\n",
    "With this in mind, complete the following function (where there's an empty line you should write a line of code that does what the comment above indicates)\n",
    "\n",
    "**Please note you will need GraphLab Create version at least 1.7.1 in order for .to_numpy() to work!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # add a constant column to an SFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    \n",
    "    features_sframe=data_sframe[features]\n",
    "    \n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    features_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "    output_sarray=data_sframe[output]\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = output_sarray.to_numpy() # GraphLab Create>= 1.7!!\n",
    "    return(features_matrix, output_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing let's use the 'sqft_living' feature and a constant as our features and price as our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00   1.18000000e+03]\n",
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') # the [] around 'sqft_living' makes it a list\n",
    "print example_features[0,:] # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print example_output[0] # and the corresponding output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 1180.0] and we wanted to compute the predicted output 1.0\\*1.0 + 1.0\\*1180.0 = 1181.0 this is the dot product between these two arrays. If they're numpy arrayws we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.]) # the example weights\n",
    "my_features = example_features[0,] # we'll use the first data point\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "print predicted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot() also works when dealing with a matrix and a vector. Recall that the predictions from all the observations is just the RIGHT (as in weights on the right) dot product between the features *matrix* and the weights *vector*. With this in mind finish the following predict_output function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions=np.dot(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test your code run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n",
      "2571.0\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print test_predictions[0] # should be 1181.0\n",
    "print test_predictions[1] # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2\n",
    "\n",
    "Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:\n",
    "\n",
    "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]\n",
    "\n",
    "The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "2\\*error\\*[feature_i]\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative=np.dot(errors,feature)\n",
    "    derivative=np.dot(2,derivative)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your feature derivartive run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-221900. -538000. -180000. ..., -402101. -400000. -325000.]\n",
      "-23345850022.0\n",
      "-23345850022.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "print errors\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print derivative\n",
    "print -np.sum(example_output)*2 # should be the same as derivative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt # recall that the magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "    predictions=predict_output(feature_matrix, initial_weights)\n",
    "    # compute the errors as predictions - output\n",
    "    errors = predictions - output\n",
    "    \n",
    "    while not converged:\n",
    "\n",
    "     \n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            feature = feature_matrix[:,i] \n",
    "            derivative = feature_derivative(errors, feature)\n",
    "            print \"derivative is \",derivative\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares =gradient_sum_squares+ derivative**2\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "                \n",
    "            weights[i]=weights[i]-step_size*derivative\n",
    "        \n",
    "        predictions=predict_output(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = math.sqrt(gradient_sum_squares)\n",
    "        print gradient_magnitude\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's split the data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the gradient descent is designed for multiple regression since the constant is now a feature we can use the gradient descent function to estimat the parameters in the simple regression on squarefeet. The folowing cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run your gradient descent with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative is  -20314476464.0\n",
      "derivative is  -5.05515266926e+13\n",
      "5.05515307744e+13\n",
      "derivative is  5276190530.64\n",
      "derivative is  1.31274499632e+13\n",
      "1.31274510235e+13\n",
      "derivative is  -1369310060.29\n",
      "derivative is  -3.40899580752e+12\n",
      "3.40899608253e+12\n",
      "derivative is  356423704.768\n",
      "derivative is  885263508348.0\n",
      "8.852635801e+11\n",
      "derivative is  -91722674.4832\n",
      "derivative is  -229889247422.0\n",
      "2.2988926572e+11\n",
      "derivative is  24654011.9039\n",
      "derivative is  59698683168.9\n",
      "59698688259.7\n",
      "derivative is  -5567214.41928\n",
      "derivative is  -15502825422.5\n",
      "15502826422.1\n",
      "derivative is  2280770.80818\n",
      "derivative is  4025843755.44\n",
      "4025844401.5\n",
      "derivative is  242770.339852\n",
      "derivative is  -1045449719.97\n",
      "1045449748.16\n",
      "derivative is  772007.520968\n",
      "derivative is  271486794.211\n",
      "271487891.86\n",
      "derivative is  634572.773602\n",
      "derivative is  -70501258.9013\n",
      "70504114.6974\n",
      "derivative is  670262.419427\n",
      "derivative is  18307751.4198\n",
      "18320016.7511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-46999.88716555,    281.91211912])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1=regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "predict1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your weights compare to those achieved in week 1 (don't expect them to be exactly the same)? \n",
    "\n",
    "**Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute your predictions using test_simple_feature_matrix and your weights from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative is  -4973089812.0\n",
      "derivative is  -1.22394025926e+13\n",
      "1.22394036029e+13\n",
      "derivative is  -3466284914.56\n",
      "derivative is  -8.51242404175e+12\n",
      "8.51242474749e+12\n",
      "derivative is  -2418312013.63\n",
      "derivative is  -5.92033495972e+12\n",
      "5.92033545363e+12\n",
      "derivative is  -1689453750.04\n",
      "derivative is  -4.11755404283e+12\n",
      "4.11755438943e+12\n",
      "derivative is  -1182537618.95\n",
      "derivative is  -2.86373176611e+12\n",
      "2.86373201026e+12\n",
      "derivative is  -829980782.025\n",
      "derivative is  -1.99170661492e+12\n",
      "1.99170678785e+12\n",
      "derivative is  -584779819.484\n",
      "derivative is  -1.38521885471e+12\n",
      "1.38521897815e+12\n",
      "derivative is  -414244161.847\n",
      "derivative is  -963410604370.0\n",
      "9.63410693428e+11\n",
      "derivative is  -295637732.943\n",
      "derivative is  -670045739105.0\n",
      "6.70045804325e+11\n",
      "derivative is  -213147741.255\n",
      "derivative is  -466012403810.0\n",
      "4.66012452556e+11\n",
      "derivative is  -155776494.23\n",
      "derivative is  -324108560370.0\n",
      "3.24108597806e+11\n",
      "derivative is  -115875168.996\n",
      "derivative is  -225415370094.0\n",
      "2.25415399877e+11\n",
      "derivative is  -88124059.5245\n",
      "derivative is  -156774905037.0\n",
      "1.56774929805e+11\n",
      "derivative is  -68823345.2439\n",
      "derivative is  -109035912814.0\n",
      "1.09035934534e+11\n",
      "derivative is  -55399825.2682\n",
      "derivative is  -75833757544.9\n",
      "75833777780.9\n",
      "derivative is  -46063855.2964\n",
      "derivative is  -52741876816.9\n",
      "52741896932.6\n",
      "derivative is  -39570749.4821\n",
      "derivative is  -36681625570.2\n",
      "36681646913.9\n",
      "derivative is  -35054837.0009\n",
      "derivative is  -25511826403.6\n",
      "25511850487.3\n",
      "derivative is  -31914049.4856\n",
      "derivative is  -17743304510.3\n",
      "17743333211.5\n",
      "derivative is  -29729652.3442\n",
      "derivative is  -12340348601.6\n",
      "12340384413.1\n",
      "derivative is  -28210418.421\n",
      "derivative is  -8582628284.65\n",
      "8582674647.23\n",
      "derivative is  -27153801.1433\n",
      "derivative is  -5969158506.38\n",
      "5969220267.6\n",
      "derivative is  -26418930.7015\n",
      "derivative is  -4151507455.8\n",
      "4151591515.97\n",
      "derivative is  -25907833.069\n",
      "derivative is  -2887343098.85\n",
      "2887459330.67\n",
      "derivative is  -25552367.9544\n",
      "derivative is  -2008125098.84\n",
      "2008287662.69\n",
      "derivative is  -25305144.2328\n",
      "derivative is  -1396634759.58\n",
      "1396863988.36\n",
      "derivative is  -25133201.6886\n",
      "derivative is  -971347248.376\n",
      "971672349.486\n",
      "derivative is  -25013616.7083\n",
      "derivative is  -675562580.059\n",
      "676025502.919\n",
      "derivative is  -24930446.0696\n",
      "derivative is  -469846287.649\n",
      "470507238.157\n",
      "derivative is  -24872601.366\n",
      "derivative is  -326771958.598\n",
      "327717193.972\n",
      "derivative is  -24832370.6839\n",
      "derivative is  -227264703.274\n",
      "228617348.397\n",
      "derivative is  -24804390.4379\n",
      "derivative is  -158058061.328\n",
      "159992526.5\n",
      "derivative is  -24784930.2896\n",
      "derivative is  -109925296.8\n",
      "112684797.759\n",
      "derivative is  -24771395.8134\n",
      "derivative is  -76449275.4811\n",
      "80362390.2838\n",
      "derivative is  -24761982.6031\n",
      "derivative is  -53166922.715\n",
      "58650468.4842\n",
      "derivative is  -24755435.7061\n",
      "derivative is  -36974199.4179\n",
      "44496325.9112\n",
      "derivative is  -24750882.3113\n",
      "derivative is  -25712266.8121\n",
      "35689309.8813\n",
      "derivative is  -24747715.384\n",
      "derivative is  -17879666.7168\n",
      "30530835.2102\n",
      "derivative is  -24745512.7359\n",
      "derivative is  -12432144.8407\n",
      "27692934.5845\n",
      "derivative is  -24743980.7375\n",
      "derivative is  -8643429.18556\n",
      "26210178.3821\n",
      "derivative is  -24742915.1716\n",
      "derivative is  -6008402.35425\n",
      "25461986.3727\n",
      "derivative is  -24742174.0065\n",
      "derivative is  -4175758.51558\n",
      "25092073.1258\n",
      "derivative is  -24741658.46\n",
      "derivative is  -2901166.77177\n",
      "24911170.8273\n"
     ]
    }
   ],
   "source": [
    "#predict1_test=regression_gradient_descent(test_simple_feature_matrix, test_output, initial_weights, step_size, tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predictions=predict_output(test_simple_feature_matrix, predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356134.44317092974"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310000.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the predictions on test data, compute the RSS on the test data set. Save this value for comparison later. Recall that RSS is the sum of the squared errors (difference between prediction and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275400047593155.94"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = test_predictions - test_output\n",
    "np.sum(errors**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use more than one actual feature. Use the following code to produce the weights for a second model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above parameters to estimate the model weights. Record these values for your quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derivative is  -22088131390.0\n",
      "derivative is  -5.42241456313e+13\n",
      "derivative is  -4.89822593371e+13\n",
      "7.30720205489e+13\n",
      "derivative is  7126218409.31\n",
      "derivative is  1.62070050891e+13\n",
      "derivative is  1.58558470033e+13\n",
      "2.26732209651e+13\n",
      "derivative is  -1941371779.99\n",
      "derivative is  -5.62333413279e+12\n",
      "derivative is  -4.27000346518e+12\n",
      "7.0607945821e+12\n",
      "derivative is  864671224.15\n",
      "derivative is  1.16169158388e+12\n",
      "derivative is  1.95683475947e+12\n",
      "2.27568239427e+12\n",
      "derivative is  -11846421.7952\n",
      "derivative is  -928924532386.0\n",
      "derivative is  10520528506.5\n",
      "9.28984105638e+11\n",
      "derivative is  253961437.694\n",
      "derivative is  -267010493601.0\n",
      "derivative is  599537128254.0\n",
      "6.56307425178e+11\n",
      "derivative is  165610625.45\n",
      "derivative is  -459137878334.0\n",
      "derivative is  402546257133.0\n",
      "6.10615351821e+11\n",
      "derivative is  187245405.404\n",
      "derivative is  -386689337854.0\n",
      "derivative is  449681823946.0\n",
      "5.93078765307e+11\n",
      "derivative is  174904044.14\n",
      "derivative is  -396606422958.0\n",
      "derivative is  421430725824.0\n",
      "5.78705920128e+11\n",
      "derivative is  173234286.778\n",
      "derivative is  -381274935306.0\n",
      "derivative is  416884889043.0\n",
      "5.64945676163e+11\n",
      "derivative is  168385074.257\n",
      "derivative is  -374065293968.0\n",
      "derivative is  405302411297.0\n",
      "5.51538681425e+11\n",
      "derivative is  164649339.053\n",
      "derivative is  -364620472137.0\n",
      "derivative is  396210671100.0\n",
      "5.38452422879e+11\n",
      "derivative is  160692569.23\n",
      "derivative is  -356146056912.0\n",
      "derivative is  386647354676.0\n",
      "5.25676912708e+11\n",
      "derivative is  156925725.694\n",
      "derivative is  -347641231744.0\n",
      "derivative is  377524109204.0\n",
      "5.1320454369e+11\n",
      "derivative is  153218465.649\n",
      "derivative is  -339409989019.0\n",
      "derivative is  368551208365.0\n",
      "5.01028100319e+11\n",
      "derivative is  149608404.708\n",
      "derivative is  -331351775524.0\n",
      "derivative is  359811707747.0\n",
      "4.89140559101e+11\n",
      "derivative is  146081131.414\n",
      "derivative is  -323491660105.0\n",
      "derivative is  351273202835.0\n",
      "4.77535065233e+11\n",
      "derivative is  142638436.082\n",
      "derivative is  -315815893998.0\n",
      "derivative is  342939257716.0\n",
      "4.66204926754e+11\n",
      "derivative is  139277147.48\n",
      "derivative is  -308322909788.0\n",
      "derivative is  334802434400.0\n",
      "4.55143610499e+11\n",
      "derivative is  135995695.312\n",
      "derivative is  -301007500274.0\n",
      "derivative is  326858857535.0\n",
      "4.44344738312e+11\n",
      "derivative is  132792073.33\n",
      "derivative is  -293865722248.0\n",
      "derivative is  319103693471.0\n",
      "4.33802083366e+11\n",
      "derivative is  129664469.658\n",
      "derivative is  -286893372341.0\n",
      "derivative is  311532548983.0\n",
      "4.23509566576e+11\n",
      "derivative is  126611069.885\n",
      "derivative is  -280086456622.0\n",
      "derivative is  304141034051.0\n",
      "4.1346125309e+11\n",
      "derivative is  123630116.772\n",
      "derivative is  -273441041896.0\n",
      "derivative is  296924894148.0\n",
      "4.03651348867e+11\n",
      "derivative is  120719890.39\n",
      "derivative is  -266953298840.0\n",
      "derivative is  289879965975.0\n",
      "3.9407419734e+11\n",
      "derivative is  117878712.977\n",
      "derivative is  -260619485715.0\n",
      "derivative is  283002188025.0\n",
      "3.84724276147e+11\n",
      "derivative is  115104946.158\n",
      "derivative is  -254435950575.0\n",
      "derivative is  276287594220.0\n",
      "3.75596193956e+11\n",
      "derivative is  112396990.559\n",
      "derivative is  -248399127804.0\n",
      "derivative is  269732312874.0\n",
      "3.66684687348e+11\n",
      "derivative is  109753284.714\n",
      "derivative is  -242505536485.0\n",
      "derivative is  263332564071.0\n",
      "3.57984617786e+11\n",
      "derivative is  107172304.219\n",
      "derivative is  -236751778258.0\n",
      "derivative is  257084657606.0\n",
      "3.49490968654e+11\n",
      "derivative is  104652560.831\n",
      "derivative is  -231134535405.0\n",
      "derivative is  250984990820.0\n",
      "3.41198842358e+11\n",
      "derivative is  102192601.621\n",
      "derivative is  -225650568920.0\n",
      "derivative is  245030046537.0\n",
      "3.33103457507e+11\n",
      "derivative is  99791008.1315\n",
      "derivative is  -220296716649.0\n",
      "derivative is  239216391027.0\n",
      "3.25200146157e+11\n",
      "derivative is  97446395.5609\n",
      "derivative is  -215069891464.0\n",
      "derivative is  233540672030.0\n",
      "3.17484351114e+11\n",
      "derivative is  95157411.9626\n",
      "derivative is  -209967079482.0\n",
      "derivative is  227999616824.0\n",
      "3.09951623311e+11\n",
      "derivative is  92922737.4672\n",
      "derivative is  -204985338330.0\n",
      "derivative is  222590030337.0\n",
      "3.02597619241e+11\n",
      "derivative is  90741083.5208\n",
      "derivative is  -200121795444.0\n",
      "derivative is  217308793301.0\n",
      "2.9541809845e+11\n",
      "derivative is  88611192.1421\n",
      "derivative is  -195373646419.0\n",
      "derivative is  212152860460.0\n",
      "2.88408921097e+11\n",
      "derivative is  86531835.1972\n",
      "derivative is  -190738153384.0\n",
      "derivative is  207119258810.0\n",
      "2.81566045563e+11\n",
      "derivative is  84501813.691\n",
      "derivative is  -186212643431.0\n",
      "derivative is  202205085885.0\n",
      "2.74885526122e+11\n",
      "derivative is  82519957.0763\n",
      "derivative is  -181794507068.0\n",
      "derivative is  197407508082.0\n",
      "2.68363510666e+11\n",
      "derivative is  80585122.5786\n",
      "derivative is  -177481196717.0\n",
      "derivative is  192723759032.0\n",
      "2.6199623848e+11\n",
      "derivative is  78696194.5374\n",
      "derivative is  -173270225247.0\n",
      "derivative is  188151138001.0\n",
      "2.55780038082e+11\n",
      "derivative is  76852083.7622\n",
      "derivative is  -169159164533.0\n",
      "derivative is  183687008331.0\n",
      "2.49711325096e+11\n",
      "derivative is  75051726.9055\n",
      "derivative is  -165145644065.0\n",
      "derivative is  179328795924.0\n",
      "2.43786600194e+11\n",
      "derivative is  73294085.8488\n",
      "derivative is  -161227349572.0\n",
      "derivative is  175073987757.0\n",
      "2.3800244707e+11\n",
      "derivative is  71578147.1043\n",
      "derivative is  -157402021696.0\n",
      "derivative is  170920130429.0\n",
      "2.32355530477e+11\n",
      "derivative is  69902921.2307\n",
      "derivative is  -153667454682.0\n",
      "derivative is  166864828752.0\n",
      "2.26842594301e+11\n",
      "derivative is  68267442.2623\n",
      "derivative is  -150021495113.0\n",
      "derivative is  162905744363.0\n",
      "2.21460459683e+11\n",
      "derivative is  66670767.1522\n",
      "derivative is  -146462040660.0\n",
      "derivative is  159040594384.0\n",
      "2.16206023185e+11\n",
      "derivative is  65111975.2287\n",
      "derivative is  -142987038879.0\n",
      "derivative is  155267150099.0\n",
      "2.11076255005e+11\n",
      "derivative is  63590167.6639\n",
      "derivative is  -139594486020.0\n",
      "derivative is  151583235672.0\n",
      "2.06068197225e+11\n",
      "derivative is  62104466.9561\n",
      "derivative is  -136282425875.0\n",
      "derivative is  147986726890.0\n",
      "2.01178962108e+11\n",
      "derivative is  60654016.4232\n",
      "derivative is  -133048948651.0\n",
      "derivative is  144475549941.0\n",
      "1.96405730433e+11\n",
      "derivative is  59237979.7091\n",
      "derivative is  -129892189866.0\n",
      "derivative is  141047680217.0\n",
      "1.91745749866e+11\n",
      "derivative is  57855540.3015\n",
      "derivative is  -126810329275.0\n",
      "derivative is  137701141146.0\n",
      "1.8719633338e+11\n",
      "derivative is  56505901.0606\n",
      "derivative is  -123801589822.0\n",
      "derivative is  134434003052.0\n",
      "1.82754857697e+11\n",
      "derivative is  55188283.7599\n",
      "derivative is  -120864236613.0\n",
      "derivative is  131244382045.0\n",
      "1.78418761783e+11\n",
      "derivative is  53901928.6375\n",
      "derivative is  -117996575917.0\n",
      "derivative is  128130438932.0\n",
      "1.74185545366e+11\n",
      "derivative is  52646093.9576\n",
      "derivative is  -115196954188.0\n",
      "derivative is  125090378156.0\n",
      "1.70052767496e+11\n",
      "derivative is  51420055.5831\n",
      "derivative is  -112463757114.0\n",
      "derivative is  122122446762.0\n",
      "1.66018045138e+11\n",
      "derivative is  50223106.5581\n",
      "derivative is  -109795408684.0\n",
      "derivative is  119224933389.0\n",
      "1.62079051799e+11\n",
      "derivative is  49054556.7001\n",
      "derivative is  -107190370279.0\n",
      "derivative is  116396167276.0\n",
      "1.58233516183e+11\n",
      "derivative is  47913732.2019\n",
      "derivative is  -104647139788.0\n",
      "derivative is  113634517307.0\n",
      "1.54479220884e+11\n",
      "derivative is  46799975.2436\n",
      "derivative is  -102164250737.0\n",
      "derivative is  110938391063.0\n",
      "1.50814001109e+11\n",
      "derivative is  45712643.6126\n",
      "derivative is  -99740271447.1\n",
      "derivative is  108306233909.0\n",
      "1.47235743424e+11\n",
      "derivative is  44651110.3337\n",
      "derivative is  -97373804208.5\n",
      "derivative is  105736528096.0\n",
      "1.43742384541e+11\n",
      "derivative is  43614763.3077\n",
      "derivative is  -95063484472.9\n",
      "derivative is  103227791885.0\n",
      "1.40331910127e+11\n",
      "derivative is  42603004.958\n",
      "derivative is  -92807980068.1\n",
      "derivative is  100778578693.0\n",
      "1.37002353639e+11\n",
      "derivative is  41615251.8863\n",
      "derivative is  -90605990429.2\n",
      "derivative is  98387476258.2\n",
      "1.33751795195e+11\n",
      "derivative is  40650934.5365\n",
      "derivative is  -88456245849.0\n",
      "derivative is  96053105828.8\n",
      "1.30578360464e+11\n",
      "derivative is  39709496.8655\n",
      "derivative is  -86357506745.8\n",
      "derivative is  93774121364.1\n",
      "1.27480219586e+11\n",
      "derivative is  38790396.0234\n",
      "derivative is  -84308562948.6\n",
      "derivative is  91549208760.1\n",
      "1.24455586117e+11\n",
      "derivative is  37893102.0399\n",
      "derivative is  -82308232999.1\n",
      "derivative is  89377085091.9\n",
      "1.21502715998e+11\n",
      "derivative is  37017097.5191\n",
      "derivative is  -80355363470.8\n",
      "derivative is  87256497873.6\n",
      "1.1861990655e+11\n",
      "derivative is  36161877.3407\n",
      "derivative is  -78448828303.7\n",
      "derivative is  85186224336.1\n",
      "1.15805495494e+11\n",
      "derivative is  35326948.3694\n",
      "derivative is  -76587528155.0\n",
      "derivative is  83165070722.1\n",
      "1.13057859988e+11\n",
      "derivative is  34511829.17\n",
      "derivative is  -74770389765.2\n",
      "derivative is  81191871597.7\n",
      "1.10375415697e+11\n",
      "derivative is  33716049.73\n",
      "derivative is  -72996365339.4\n",
      "derivative is  79265489180.5\n",
      "1.07756615874e+11\n",
      "derivative is  32939151.1884\n",
      "derivative is  -71264431942.8\n",
      "derivative is  77384812683.5\n",
      "1.05199950471e+11\n",
      "derivative is  32180685.5715\n",
      "derivative is  -69573590911.3\n",
      "derivative is  75548757674.3\n",
      "1.0270394527e+11\n",
      "derivative is  31440215.5343\n",
      "derivative is  -67922867275.2\n",
      "derivative is  73756265450.5\n",
      "1.00267161028e+11\n",
      "derivative is  30717314.1083\n",
      "derivative is  -66311309197.3\n",
      "derivative is  72006302428.3\n",
      "97888192650.6\n",
      "derivative is  30011564.4554\n",
      "derivative is  -64737987423.9\n",
      "derivative is  70297859547.5\n",
      "95565668382.2\n",
      "derivative is  29322559.6276\n",
      "derivative is  -63201994749.2\n",
      "derivative is  68629951688.7\n",
      "93298249012.9\n",
      "derivative is  28649902.3321\n",
      "derivative is  -61702445491.9\n",
      "derivative is  67001617106.1\n",
      "91084627107.5\n",
      "derivative is  27993204.7027\n",
      "derivative is  -60238474984.6\n",
      "derivative is  65411916872.3\n",
      "88923526251.5\n",
      "derivative is  27352088.0755\n",
      "derivative is  -58809239075.5\n",
      "derivative is  63859934337.4\n",
      "86813700314.9\n",
      "derivative is  26726182.7711\n",
      "derivative is  -57413913641.1\n",
      "derivative is  62344774600.1\n",
      "84753932733.7\n",
      "derivative is  26115127.8811\n",
      "derivative is  -56051694111.5\n",
      "derivative is  60865563991.8\n",
      "82743035808.5\n",
      "derivative is  25518571.0601\n",
      "derivative is  -54721795006.2\n",
      "derivative is  59421449572.7\n",
      "80779850019.8\n",
      "derivative is  24936168.3227\n",
      "derivative is  -53423449481.1\n",
      "derivative is  58011598640.2\n",
      "78863243358.8\n",
      "derivative is  24367583.8449\n",
      "derivative is  -52155908886.8\n",
      "derivative is  56635198248.9\n",
      "76992110675.6\n",
      "derivative is  23812489.7706\n",
      "derivative is  -50918442336.2\n",
      "derivative is  55291454741.1\n",
      "75165373040.8\n",
      "derivative is  23270566.0225\n",
      "derivative is  -49710336283.8\n",
      "derivative is  53979593290.0\n",
      "73381977124.6\n",
      "derivative is  22741500.1175\n",
      "derivative is  -48530894113.6\n",
      "derivative is  52698857452.5\n",
      "71640894588.5\n",
      "derivative is  22224986.9866\n",
      "derivative is  -47379435737.8\n",
      "derivative is  51448508733.0\n",
      "69941121492.5\n",
      "derivative is  21720728.799\n",
      "derivative is  -46255297204.7\n",
      "derivative is  50227826157.8\n",
      "68281677716.8\n",
      "derivative is  21228434.7902\n",
      "derivative is  -45157830315.6\n",
      "derivative is  49036105859.1\n",
      "66661606395.9\n",
      "derivative is  20747821.0946\n",
      "derivative is  -44086402251.2\n",
      "derivative is  47872660669.4\n",
      "65079973367.3\n",
      "derivative is  20278610.5817\n",
      "derivative is  -43040395206.5\n",
      "derivative is  46736819725.0\n",
      "63535866632.7\n",
      "derivative is  19820532.6961\n",
      "derivative is  -42019206035.0\n",
      "derivative is  45627928079.6\n",
      "62028395832.0\n",
      "derivative is  19373323.3018\n",
      "derivative is  -41022245900.3\n",
      "derivative is  44545346325.9\n",
      "60556691730.4\n",
      "derivative is  18936724.5298\n",
      "derivative is  -40048939937.3\n",
      "derivative is  43488450227.7\n",
      "59119905716.4\n",
      "derivative is  18510484.6294\n",
      "derivative is  -39098726920.0\n",
      "derivative is  42456630359.6\n",
      "57717209313.2\n",
      "derivative is  18094357.8227\n",
      "derivative is  -38171058938.4\n",
      "derivative is  41449291755.5\n",
      "56347793700.5\n",
      "derivative is  17688104.1637\n",
      "derivative is  -37265401082.2\n",
      "derivative is  40465853565.6\n",
      "55010869248.6\n",
      "derivative is  17291489.3991\n",
      "derivative is  -36381231132.7\n",
      "derivative is  39505748721.7\n",
      "53705665062.4\n",
      "derivative is  16904284.8335\n",
      "derivative is  -35518039261.5\n",
      "derivative is  38568423609.8\n",
      "52431428537.5\n",
      "derivative is  16526267.1979\n",
      "derivative is  -34675327736.4\n",
      "derivative is  37653337751.3\n",
      "51187424926.0\n",
      "derivative is  16157218.5204\n",
      "derivative is  -33852610634.7\n",
      "derivative is  36759963491.1\n",
      "49972936913.0\n",
      "derivative is  15796926.0008\n",
      "derivative is  -33049413562.8\n",
      "derivative is  35887785693.3\n",
      "48787264202.4\n",
      "derivative is  15445181.888\n",
      "derivative is  -32265273382.6\n",
      "derivative is  35036301444.5\n",
      "47629723114.0\n",
      "derivative is  15101783.3599\n",
      "derivative is  -31499737944.7\n",
      "derivative is  34205019763.2\n",
      "46499646188.5\n",
      "derivative is  14766532.4067\n",
      "derivative is  -30752365827.5\n",
      "derivative is  33393461317.5\n",
      "45396381803.0\n",
      "derivative is  14439235.7167\n",
      "derivative is  -30022726082.7\n",
      "derivative is  32601158148.0\n",
      "44319293795.4\n",
      "derivative is  14119704.5645\n",
      "derivative is  -29310397986.6\n",
      "derivative is  31827653398.3\n",
      "43267761097.0\n",
      "derivative is  13807754.7029\n",
      "derivative is  -28614970798.1\n",
      "derivative is  31072501051.5\n",
      "42241177375.0\n",
      "derivative is  13503206.2557\n",
      "derivative is  -27936043521.2\n",
      "derivative is  30335265673.1\n",
      "41238950682.7\n",
      "derivative is  13205883.6149\n",
      "derivative is  -27273224674.0\n",
      "derivative is  29615522159.8\n",
      "40260503117.9\n",
      "derivative is  12915615.3389\n",
      "derivative is  -26626132063.2\n",
      "derivative is  28912855494.4\n",
      "39305270490.1\n",
      "derivative is  12632234.0537\n",
      "derivative is  -25994392563.5\n",
      "derivative is  28226860506.5\n",
      "38372701994.6\n",
      "derivative is  12355576.3565\n",
      "derivative is  -25377641902.3\n",
      "derivative is  27557141638.9\n",
      "37462259895.7\n",
      "derivative is  12085482.7214\n",
      "derivative is  -24775524450.2\n",
      "derivative is  26903312719.8\n",
      "36573419215.8\n",
      "derivative is  11821797.4077\n",
      "derivative is  -24187693015.1\n",
      "derivative is  26264996739.3\n",
      "35705667433.4\n",
      "derivative is  11564368.3695\n",
      "derivative is  -23613808642.9\n",
      "derivative is  25641825632.9\n",
      "34858504186.9\n",
      "derivative is  11313047.1686\n",
      "derivative is  -23053540421.3\n",
      "derivative is  25033440068.9\n",
      "34031440986.6\n",
      "derivative is  11067688.8886\n",
      "derivative is  -22506565289.7\n",
      "derivative is  24439489241.1\n",
      "33224000933.0\n",
      "derivative is  10828152.0516\n",
      "derivative is  -21972567852.1\n",
      "derivative is  23859630666.6\n",
      "32435718441.4\n",
      "derivative is  10594298.5362\n",
      "derivative is  -21451240195.9\n",
      "derivative is  23293529988.6\n",
      "31666138973.8\n",
      "derivative is  10365993.4983\n",
      "derivative is  -20942281714.3\n",
      "derivative is  22740860782.9\n",
      "30914818776.8\n",
      "derivative is  10143105.2931\n",
      "derivative is  -20445398932.4\n",
      "derivative is  22201304370.7\n",
      "30181324625.4\n",
      "derivative is  9925505.39909\n",
      "derivative is  -19960305338.6\n",
      "derivative is  21674549633.8\n",
      "29465233573.7\n",
      "derivative is  9713068.34433\n",
      "derivative is  -19486721219.2\n",
      "derivative is  21160292835.8\n",
      "28766132710.5\n",
      "derivative is  9505671.63374\n",
      "derivative is  -19024373497.0\n",
      "derivative is  20658237447.1\n",
      "28083618921.5\n",
      "derivative is  9303195.67864\n",
      "derivative is  -18572995573.8\n",
      "derivative is  20168093973.3\n",
      "27417298657.0\n",
      "derivative is  9105523.7277\n",
      "derivative is  -18132327177.0\n",
      "derivative is  19689579788.8\n",
      "26766787704.6\n",
      "derivative is  8912541.79972\n",
      "derivative is  -17702114209.2\n",
      "derivative is  19222418973.7\n",
      "26131710967.9\n",
      "derivative is  8724138.61781\n",
      "derivative is  -17282108601.8\n",
      "derivative is  18766342154.5\n",
      "25511702250.0\n",
      "derivative is  8540205.54528\n",
      "derivative is  -16872068171.9\n",
      "derivative is  18321086349.1\n",
      "24906404042.8\n",
      "derivative is  8360636.523\n",
      "derivative is  -16471756482.7\n",
      "derivative is  17886394814.9\n",
      "24315467320.2\n",
      "derivative is  8185328.00822\n",
      "derivative is  -16080942707.3\n",
      "derivative is  17462016900.8\n",
      "23738551337.5\n",
      "derivative is  8014178.91487\n",
      "derivative is  -15699401495.4\n",
      "derivative is  17047707903.0\n",
      "23175323434.3\n",
      "derivative is  7847090.55529\n",
      "derivative is  -15326912843.3\n",
      "derivative is  16643228923.1\n",
      "22625458843.3\n",
      "derivative is  7683966.58331\n",
      "derivative is  -14963261967.4\n",
      "derivative is  16248346731.4\n",
      "22088640502.6\n",
      "derivative is  7524712.93868\n",
      "derivative is  -14608239179.9\n",
      "derivative is  15862833631.7\n",
      "21564558873.0\n",
      "derivative is  7369237.79288\n",
      "derivative is  -14261639768.3\n",
      "derivative is  15486467330.0\n",
      "21052911759.4\n",
      "derivative is  7217451.49613\n",
      "derivative is  -13923263877.1\n",
      "derivative is  15119030806.6\n",
      "20553404136.9\n",
      "derivative is  7069266.52569\n",
      "derivative is  -13592916392.5\n",
      "derivative is  14760312191.2\n",
      "20065747980.3\n",
      "derivative is  6924597.43543\n",
      "derivative is  -13270406830.3\n",
      "derivative is  14410104639.9\n",
      "19589662098.2\n",
      "derivative is  6783360.80655\n",
      "derivative is  -12955549225.5\n",
      "derivative is  14068206216.8\n",
      "19124871970.9\n",
      "derivative is  6645475.19943\n",
      "derivative is  -12648162025.5\n",
      "derivative is  13734419776.9\n",
      "18671109592.0\n",
      "derivative is  6510861.10675\n",
      "derivative is  -12348067985.4\n",
      "derivative is  13408552853.1\n",
      "18228113313.7\n",
      "derivative is  6379440.90758\n",
      "derivative is  -12055094065.3\n",
      "derivative is  13090417544.5\n",
      "17795627696.4\n",
      "derivative is  6251138.82267\n",
      "derivative is  -11769071331.4\n",
      "derivative is  12779830408.5\n",
      "17373403361.1\n",
      "derivative is  6125880.8707\n",
      "derivative is  -11489834857.6\n",
      "derivative is  12476612354.9\n",
      "16961196845.6\n",
      "derivative is  6003594.82568\n",
      "derivative is  -11217223631.1\n",
      "derivative is  12180588542.7\n",
      "16558770464.0\n",
      "derivative is  5884210.17527\n",
      "derivative is  -10951080459.3\n",
      "derivative is  11891588279.2\n",
      "16165892170.0\n",
      "derivative is  5767658.08011\n",
      "derivative is  -10691251879.4\n",
      "derivative is  11609444921.6\n",
      "15782335422.9\n",
      "derivative is  5653871.33415\n",
      "derivative is  -10437588069.3\n",
      "derivative is  11333995781.0\n",
      "15407879056.9\n",
      "derivative is  5542784.32591\n",
      "derivative is  -10189942761.9\n",
      "derivative is  11065082028.2\n",
      "15042307153.7\n",
      "derivative is  5434333.00061\n",
      "derivative is  -9948173160.54\n",
      "derivative is  10802548602.9\n",
      "14685408917.8\n",
      "derivative is  5328454.82325\n",
      "derivative is  -9712139856.35\n",
      "derivative is  10546244123.4\n",
      "14336978555.2\n",
      "derivative is  5225088.74256\n",
      "derivative is  -9481706748.29\n",
      "derivative is  10296020800.0\n",
      "13996815154.7\n",
      "derivative is  5124175.1558\n",
      "derivative is  -9256740964.45\n",
      "derivative is  10051734349.3\n",
      "13664722572.0\n",
      "derivative is  5025655.87436\n",
      "derivative is  -9037112785.46\n",
      "derivative is  9813243911.29\n",
      "13340509316.2\n",
      "derivative is  4929474.09024\n",
      "derivative is  -8822695569.74\n",
      "derivative is  9580411968.11\n",
      "13023988440.4\n",
      "derivative is  4835574.3433\n",
      "derivative is  -8613365680.42\n",
      "derivative is  9353104264.62\n",
      "12714977432.6\n",
      "derivative is  4743902.48923\n",
      "derivative is  -8409002414.09\n",
      "derivative is  9131189731.06\n",
      "12413298111.7\n",
      "derivative is  4654405.66841\n",
      "derivative is  -8209487931.18\n",
      "derivative is  8914540407.49\n",
      "12118776523.7\n",
      "derivative is  4567032.27533\n",
      "derivative is  -8014707188.02\n",
      "derivative is  8703031369.98\n",
      "11831242842.3\n",
      "derivative is  4481731.92893\n",
      "derivative is  -7824547870.5\n",
      "derivative is  8496540658.57\n",
      "11550531270.3\n",
      "derivative is  4398455.44349\n",
      "derivative is  -7638900329.3\n",
      "derivative is  8294949206.98\n",
      "11276479944.3\n",
      "derivative is  4317154.80028\n",
      "derivative is  -7457657516.68\n",
      "derivative is  8098140773.91\n",
      "11008930841.3\n",
      "derivative is  4237783.11988\n",
      "derivative is  -7280714924.74\n",
      "derivative is  7906001876.05\n",
      "10747729687.6\n",
      "derivative is  4160294.63515\n",
      "derivative is  -7107970525.18\n",
      "derivative is  7718421722.62\n",
      "10492725870.0\n",
      "derivative is  4084644.66484\n",
      "derivative is  -6939324710.44\n",
      "derivative is  7535292151.51\n",
      "10243772348.6\n",
      "derivative is  4010789.58779\n",
      "derivative is  -6774680236.27\n",
      "derivative is  7356507566.86\n",
      "10000725572.3\n",
      "derivative is  3938686.81785\n",
      "derivative is  -6613942165.7\n",
      "derivative is  7181964878.26\n",
      "9763445395.81\n",
      "derivative is  3868294.77926\n",
      "derivative is  -6457017814.22\n",
      "derivative is  7011563441.21\n",
      "9531794999.22\n",
      "derivative is  3799572.88269\n",
      "derivative is  -6303816696.41\n",
      "derivative is  6845204999.16\n",
      "9305640808.63\n",
      "derivative is  3732481.50187\n",
      "derivative is  -6154250473.72\n",
      "derivative is  6682793626.82\n",
      "9084852419.46\n",
      "derivative is  3666981.95068\n",
      "derivative is  -6008232903.57\n",
      "derivative is  6524235674.81\n",
      "8869302521.1\n",
      "derivative is  3603036.46092\n",
      "derivative is  -5865679789.55\n",
      "derivative is  6369439715.77\n",
      "8658866823.56\n",
      "derivative is  3540608.16046\n",
      "derivative is  -5726508932.96\n",
      "derivative is  6218316491.53\n",
      "8453423985.82\n",
      "derivative is  3479661.05201\n",
      "derivative is  -5590640085.36\n",
      "derivative is  6070778861.69\n",
      "8252855545.78\n",
      "derivative is  3420159.99238\n",
      "derivative is  -5457994902.3\n",
      "derivative is  5926741753.38\n",
      "8057045852.07\n",
      "derivative is  3362070.67218\n",
      "derivative is  -5328496898.17\n",
      "derivative is  5786122112.19\n",
      "7865881997.24\n",
      "derivative is  3305359.59606\n",
      "derivative is  -5202071402.06\n",
      "derivative is  5648838854.28\n",
      "7679253752.75\n",
      "derivative is  3249994.0634\n",
      "derivative is  -5078645514.73\n",
      "derivative is  5514812819.63\n",
      "7497053505.37\n",
      "derivative is  3195942.14944\n",
      "derivative is  -4958148066.6\n",
      "derivative is  5383966726.39\n",
      "7319176195.12\n",
      "derivative is  3143172.68686\n",
      "derivative is  -4840509576.61\n",
      "derivative is  5256225126.36\n",
      "7145519254.73\n",
      "derivative is  3091655.24785\n",
      "derivative is  -4725662212.31\n",
      "derivative is  5131514361.37\n",
      "6975982550.45\n",
      "derivative is  3041360.12652\n",
      "derivative is  -4613539750.61\n",
      "derivative is  5009762520.95\n",
      "6810468324.33\n",
      "derivative is  2992258.32181\n",
      "derivative is  -4504077539.67\n",
      "derivative is  4890899400.78\n",
      "6648881137.87\n",
      "derivative is  2944321.52072\n",
      "derivative is  -4397212461.58\n",
      "derivative is  4774856462.23\n",
      "6491127816.97\n",
      "derivative is  2897522.08204\n",
      "derivative is  -4292882896.01\n",
      "derivative is  4661566792.82\n",
      "6337117398.19\n",
      "derivative is  2851833.02037\n",
      "derivative is  -4191028684.62\n",
      "derivative is  4550965067.69\n",
      "6186761076.33\n",
      "derivative is  2807227.99057\n",
      "derivative is  -4091591096.44\n",
      "derivative is  4442987511.86\n",
      "6039972153.21\n",
      "derivative is  2763681.27259\n",
      "derivative is  -3994512793.95\n",
      "derivative is  4337571863.52\n",
      "5896665987.68\n",
      "derivative is  2721167.75661\n",
      "derivative is  -3899737800.03\n",
      "derivative is  4234657338.1\n",
      "5756759946.78\n",
      "derivative is  2679662.92856\n",
      "derivative is  -3807211465.71\n",
      "derivative is  4134184593.21\n",
      "5620173358.17\n",
      "derivative is  2639142.85602\n",
      "derivative is  -3716880438.61\n",
      "derivative is  4036095694.43\n",
      "5486827463.54\n",
      "derivative is  2599584.17438\n",
      "derivative is  -3628692632.23\n",
      "derivative is  3940334081.94\n",
      "5356645373.21\n",
      "derivative is  2560964.07341\n",
      "derivative is  -3542597195.88\n",
      "derivative is  3846844537.85\n",
      "5229552021.85\n",
      "derivative is  2523260.28406\n",
      "derivative is  -3458544485.37\n",
      "derivative is  3755573154.39\n",
      "5105474125.1\n",
      "derivative is  2486451.06565\n",
      "derivative is  -3376486034.38\n",
      "derivative is  3666467302.82\n",
      "4984340137.41\n",
      "derivative is  2450515.19332\n",
      "derivative is  -3296374526.51\n",
      "derivative is  3579475603.09\n",
      "4866080210.72\n",
      "derivative is  2415431.9458\n",
      "derivative is  -3218163768.03\n",
      "derivative is  3494547894.2\n",
      "4750626154.21\n",
      "derivative is  2381181.09347\n",
      "derivative is  -3141808661.18\n",
      "derivative is  3411635205.31\n",
      "4637911394.97\n",
      "derivative is  2347742.88667\n",
      "derivative is  -3067265178.22\n",
      "derivative is  3330689727.45\n",
      "4527870939.63\n",
      "derivative is  2315098.04434\n",
      "derivative is  -2994490336.02\n",
      "derivative is  3251664785.98\n",
      "4420441336.86\n",
      "derivative is  2283227.74286\n",
      "derivative is  -2923442171.31\n",
      "derivative is  3174514813.69\n",
      "4315560640.81\n",
      "derivative is  2252113.60526\n",
      "derivative is  -2854079716.4\n",
      "derivative is  3099195324.52\n",
      "4213168375.35\n",
      "derivative is  2221737.69057\n",
      "derivative is  -2786362975.66\n",
      "derivative is  3025662887.85\n",
      "4113205499.26\n",
      "derivative is  2192082.48349\n",
      "derivative is  -2720252902.37\n",
      "derivative is  2953875103.58\n",
      "4015614372.13\n",
      "derivative is  2163130.8843\n",
      "derivative is  -2655711376.27\n",
      "derivative is  2883790577.55\n",
      "3920338721.13\n",
      "derivative is  2134866.19899\n",
      "derivative is  -2592701181.55\n",
      "derivative is  2815368897.76\n",
      "3827323608.6\n",
      "derivative is  2107272.12964\n",
      "derivative is  -2531185985.38\n",
      "derivative is  2748570611.02\n",
      "3736515400.34\n",
      "derivative is  2080332.76502\n",
      "derivative is  -2471130316.99\n",
      "derivative is  2683357200.22\n",
      "3647861734.68\n",
      "derivative is  2054032.5714\n",
      "derivative is  -2412499547.19\n",
      "derivative is  2619691062.14\n",
      "3561311492.31\n",
      "derivative is  2028356.38363\n",
      "derivative is  -2355259868.4\n",
      "derivative is  2557535485.71\n",
      "3476814766.79\n",
      "derivative is  2003289.39635\n",
      "derivative is  -2299378275.2\n",
      "derivative is  2496854630.92\n",
      "3394322835.78\n",
      "derivative is  1978817.15551\n",
      "derivative is  -2244822545.23\n",
      "derivative is  2437613508.06\n",
      "3313788132.94\n",
      "derivative is  1954925.54996\n",
      "derivative is  -2191561220.69\n",
      "derivative is  2379777957.65\n",
      "3235164220.48\n",
      "derivative is  1931600.80338\n",
      "derivative is  -2139563590.12\n",
      "derivative is  2323314630.63\n",
      "3158405762.43\n",
      "derivative is  1908829.46631\n",
      "derivative is  -2088799670.73\n",
      "derivative is  2268190969.26\n",
      "3083468498.48\n",
      "derivative is  1886598.40839\n",
      "derivative is  -2039240191.14\n",
      "derivative is  2214375188.21\n",
      "3010309218.43\n",
      "derivative is  1864894.8108\n",
      "derivative is  -1990856574.46\n",
      "derivative is  2161836256.33\n",
      "2938885737.33\n",
      "derivative is  1843706.15885\n",
      "derivative is  -1943620921.8\n",
      "derivative is  2110543878.71\n",
      "2869156871.08\n",
      "derivative is  1823020.2348\n",
      "derivative is  -1897505996.23\n",
      "derivative is  2060468479.25\n",
      "2801082412.77\n",
      "derivative is  1802825.11077\n",
      "derivative is  -1852485207.06\n",
      "derivative is  2011581183.56\n",
      "2734623109.42\n",
      "derivative is  1783109.14189\n",
      "derivative is  -1808532594.47\n",
      "derivative is  1963853802.33\n",
      "2669740639.4\n",
      "derivative is  1763860.9596\n",
      "derivative is  -1765622814.6\n",
      "derivative is  1917258815.09\n",
      "2606397590.29\n",
      "derivative is  1745069.46504\n",
      "derivative is  -1723731124.87\n",
      "derivative is  1871769354.33\n",
      "2544557437.34\n",
      "derivative is  1726723.8227\n",
      "derivative is  -1682833369.79\n",
      "derivative is  1827359190.0\n",
      "2484184522.4\n",
      "derivative is  1708813.45417\n",
      "derivative is  -1642905966.98\n",
      "derivative is  1784002714.38\n",
      "2425244033.35\n",
      "derivative is  1691328.03202\n",
      "derivative is  -1603925893.55\n",
      "derivative is  1741674927.36\n",
      "2367701984.03\n",
      "derivative is  1674257.47382\n",
      "derivative is  -1565870672.9\n",
      "derivative is  1700351421.95\n",
      "2311525194.65\n",
      "derivative is  1657591.93641\n",
      "derivative is  -1528718361.68\n",
      "derivative is  1660008370.29\n",
      "2256681272.66\n",
      "derivative is  1641321.81014\n",
      "derivative is  -1492447537.22\n",
      "derivative is  1620622509.82\n",
      "2203138594.06\n",
      "derivative is  1625437.71336\n",
      "derivative is  -1457037285.09\n",
      "derivative is  1582171129.94\n",
      "2150866285.15\n",
      "derivative is  1609930.48703\n",
      "derivative is  -1422467187.09\n",
      "derivative is  1544632058.91\n",
      "2099834204.79\n",
      "derivative is  1594791.1894\n",
      "derivative is  -1388717309.48\n",
      "derivative is  1507983650.99\n",
      "2050012926.95\n",
      "derivative is  1580011.09089\n",
      "derivative is  -1355768191.47\n",
      "derivative is  1472204774.07\n",
      "2001373723.78\n",
      "derivative is  1565581.66904\n",
      "derivative is  -1323600834.0\n",
      "derivative is  1437274797.38\n",
      "1953888549.02\n",
      "derivative is  1551494.60359\n",
      "derivative is  -1292196688.79\n",
      "derivative is  1403173579.67\n",
      "1907530021.87\n",
      "derivative is  1537741.77168\n",
      "derivative is  -1261537647.63\n",
      "derivative is  1369881457.56\n",
      "1862271411.15\n",
      "derivative is  1524315.2432\n",
      "derivative is  -1231606031.96\n",
      "derivative is  1337379234.2\n",
      "1818086619.93\n",
      "derivative is  1511207.27617\n",
      "derivative is  -1202384582.69\n",
      "derivative is  1305648168.22\n",
      "1774950170.46\n",
      "derivative is  1498410.31231\n",
      "derivative is  -1173856450.17\n",
      "derivative is  1274669962.93\n",
      "1732837189.48\n",
      "derivative is  1485916.97266\n",
      "derivative is  -1146005184.59\n",
      "derivative is  1244426755.71\n",
      "1691723393.87\n",
      "derivative is  1473720.05335\n",
      "derivative is  -1118814726.38\n",
      "derivative is  1214901107.78\n",
      "1651585076.68\n",
      "derivative is  1461812.52142\n",
      "derivative is  -1092269397.05\n",
      "derivative is  1186075994.14\n",
      "1612399093.43\n",
      "derivative is  1450187.51078\n",
      "derivative is  -1066353890.06\n",
      "derivative is  1157934793.68\n",
      "1574142848.76\n",
      "derivative is  1438838.31825\n",
      "derivative is  -1041053262.08\n",
      "derivative is  1130461279.68\n",
      "1536794283.43\n",
      "derivative is  1427758.39968\n",
      "derivative is  -1016352924.29\n",
      "derivative is  1103639610.42\n",
      "1500331861.58\n",
      "derivative is  1416941.3662\n",
      "derivative is  -992238634.033\n",
      "derivative is  1077454320.03\n",
      "1464734558.32\n",
      "derivative is  1406380.98052\n",
      "derivative is  -968696486.579\n",
      "derivative is  1051890309.6\n",
      "1429981847.59\n",
      "derivative is  1396071.15334\n",
      "derivative is  -945712907.087\n",
      "derivative is  1026932838.46\n",
      "1396053690.35\n",
      "derivative is  1386005.93983\n",
      "derivative is  -923274642.815\n",
      "derivative is  1002567515.67\n",
      "1362930523.01\n",
      "derivative is  1376179.53622\n",
      "derivative is  -901368755.454\n",
      "derivative is  978780291.754\n",
      "1330593246.15\n",
      "derivative is  1366586.27643\n",
      "derivative is  -879982613.662\n",
      "derivative is  955557450.566\n",
      "1299023213.51\n",
      "derivative is  1357220.62882\n",
      "derivative is  -859103885.818\n",
      "derivative is  932885601.381\n",
      "1268202221.23\n",
      "derivative is  1348077.193\n",
      "derivative is  -838720532.85\n",
      "derivative is  910751671.216\n",
      "1238112497.38\n",
      "derivative is  1339150.69671\n",
      "derivative is  -818820801.361\n",
      "derivative is  889142897.233\n",
      "1208736691.66\n",
      "derivative is  1330435.99277\n",
      "derivative is  -799393216.79\n",
      "derivative is  868046819.434\n",
      "1180057865.46\n",
      "derivative is  1321928.05614\n",
      "derivative is  -780426576.859\n",
      "derivative is  847451273.418\n",
      "1152059482.05\n",
      "derivative is  1313621.981\n",
      "derivative is  -761909945.039\n",
      "derivative is  827344383.438\n",
      "1124725397.05\n",
      "derivative is  1305512.97791\n",
      "derivative is  -743832644.317\n",
      "derivative is  807714555.485\n",
      "1098039849.12\n",
      "derivative is  1297596.37109\n",
      "derivative is  -726184250.989\n",
      "derivative is  788550470.649\n",
      "1071987450.91\n",
      "derivative is  1289867.59569\n",
      "derivative is  -708954588.674\n",
      "derivative is  769841078.566\n",
      "1046553180.11\n",
      "derivative is  1282322.19516\n",
      "derivative is  -692133722.427\n",
      "derivative is  751575591.07\n",
      "1021722370.88\n",
      "derivative is  1274955.8187\n",
      "derivative is  -675711953.045\n",
      "derivative is  733743475.936\n",
      "997480705.317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -9.99999688e+04,   2.45072603e+02,   6.52795277e+01])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2=regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "#predict2_test = regression_gradient_descent(test_feature_matrix, test_output, initial_weights, step_size, tolerance)\n",
    "test_predictions2=predict_output(test_feature_matrix, predict2)\n",
    "\n",
    "# just like SFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366651.41203655908"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the actual price for the 1st house in the test data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which estimate was closer to the true price for the 1st house on the TEST data set, model 1 or model 2?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46134.443170929735"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions[0]-test_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your predictions and the output to compute the RSS for model 2 on TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56651.412036559079"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions2[0]-test_output[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which model (1 or 2) has lowest RSS on all of the TEST data? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270263446465244.06"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors2 = test_predictions2 - test_output\n",
    "np.sum(errors2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  46134.44317093,  134640.86422788,  202069.83652353, ...,\n",
       "         52733.65300782,  204217.10799338, -161550.5256668 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  56651.41203656,  112662.39786164,  153312.09499712, ...,\n",
       "         71402.39928241,  185579.27865729, -185541.79603383])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5136601127911.875"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(errors**2)-np.sum(errors2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
