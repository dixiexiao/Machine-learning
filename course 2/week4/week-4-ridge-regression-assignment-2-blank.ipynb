{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 4: Ridge Regression (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will implement ridge regression via gradient descent. You will:\n",
    "* Convert an SFrame into a Numpy array\n",
    "* Write a Numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size, tolerance, and L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of GraphLab Create (>= 1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to dxiao@bloomu.edu and will expire on April 02, 2020.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\danqi\\AppData\\Local\\Temp\\graphlab_server_1559171020.log.0\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do any \"feature engineering\" like creating new features or adjusting existing ones we should do this directly using the SFrames as seen in the first notebook of Week 2. For this notebook, however, we will work with the existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful functions from previous notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we convert the SFrame into a 2D Numpy array. Copy and paste `get_numpy_data()` from the second notebook of Week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # add a constant column to an SFrame\n",
    "    # prepend variable 'constant' to the features list\n",
    "    features = ['constant'] + features\n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    \n",
    "    features_sframe=data_sframe[features]\n",
    "    \n",
    "    # this will convert the features_sframe into a numpy matrix with GraphLab Create >= 1.7!!\n",
    "    features_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "    output_sarray=data_sframe[output]\n",
    "    # this will convert the SArray into a numpy array:\n",
    "    output_array = output_sarray.to_numpy() # GraphLab Create>= 1.7!!\n",
    "    return(features_matrix, output_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, copy and paste the `predict_output()` function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions=np.dot(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output, plus the L2 penalty term.\n",
    "```\n",
    "Cost(w)\n",
    "= SUM[ (prediction - output)^2 ]\n",
    "+ l2_penalty*(w[0]^2 + w[1]^2 + ... + w[k]^2).\n",
    "```\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives, we can take the derivative of the first part (the RSS) as we did in the notebook for the unregularized case in Week 2 and add the derivative of the regularization part.  As we saw, the derivative of the RSS with respect to `w[i]` can be written as: \n",
    "```\n",
    "2*SUM[ error*[feature_i] ].\n",
    "```\n",
    "The derivative of the regularization term with respect to `w[i]` is:\n",
    "```\n",
    "2*l2_penalty*w[i].\n",
    "```\n",
    "Summing both, we get\n",
    "```\n",
    "2*SUM[ error*[feature_i] ] + 2*l2_penalty*w[i].\n",
    "```\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself, plus `2*l2_penalty*w[i]`. \n",
    "\n",
    "**We will not regularize the constant.**  Thus, in the case of the constant, the derivative is just twice the sum of the errors (without the `2*l2_penalty*w[0]` term).\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors, plus `2*l2_penalty*w[i]`.\n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points).  To decide when to we are dealing with the constant (so we don't regularize it) we added the extra parameter to the call `feature_is_constant` which you should set to `True` when computing the derivative of the constant and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_ridge(errors, feature, weight, l2_penalty, feature_is_constant):\n",
    "    # If feature_is_constant is True, derivative is twice the dot product of errors and feature\n",
    "    \n",
    "    if feature_is_constant==True:\n",
    "        derivative=2*np.dot(errors,feature)\n",
    "    # Otherwise, derivative is twice the dot product plus 2*l2_penalty*weight\n",
    "    else:\n",
    "        derivative=2*(np.dot(errors,feature)+2*l2_penalty*weight).sum()\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your feature derivartive run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.65541667823e+13\n",
      "-5.65541667824e+13\n",
      "\n",
      "-22446749336.0\n",
      "-22446749336.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([1., 10.])\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "errors = test_predictions - example_output # prediction errors\n",
    "\n",
    "# next two lines should print the same values\n",
    "print feature_derivative_ridge(errors, example_features[:,1], my_weights[1], 1, False)\n",
    "print np.sum(errors*example_features[:,1])*2+20.\n",
    "print ''\n",
    "\n",
    "# next two lines should print the same values\n",
    "print feature_derivative_ridge(errors, example_features[:,0], my_weights[0], 1, True)\n",
    "print np.sum(errors)*2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. Unlike in Week 2, this time we will set a **maximum number of iterations** and take gradient steps until we reach this maximum number. If no maximum number is supplied, the maximum should be set 100 by default. (Use default parameter values in Python.)\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent, we update the weight for each feature before computing our stopping criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, l2_penalty, max_iterations):\n",
    "    print 'Starting gradient descent with l2_penalty = ' + str(l2_penalty)\n",
    "    \n",
    "    weights = initial_weights # make sure it's a numpy array\n",
    "    iteration = 0 # iteration counter\n",
    "    print_frequency = 1  # for adjusting frequency of debugging output\n",
    "    \n",
    "    cost=[1e50]\n",
    "    #while not reached maximum number of iterations:\n",
    "    while iteration<max_iterations: \n",
    "        predictions=predict_output(feature_matrix, weights)\n",
    "        errors = predictions - output\n",
    "        iteration += 1  # increment iteration counter\n",
    "        ### === code section for adjusting frequency of debugging output. ===\n",
    "        if iteration == 10:\n",
    "            print_frequency = 10\n",
    "        if iteration == 100:\n",
    "            print_frequency = 100\n",
    "        if iteration%print_frequency==0:\n",
    "            print('Iteration = ' + str(iteration))\n",
    "        ### === end code section ===\n",
    "        if iteration%print_frequency==0:\n",
    "            print 'Cost function = ', str(np.dot(errors,errors) + l2_penalty*(np.dot(weights,weights) - weights[0]**2))\n",
    "        \n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        ctemp=np.dot(errors,errors) + l2_penalty*(np.dot(weights,weights) - weights[0]**2)       \n",
    "               \n",
    "        if ctemp<=cost[-1]:\n",
    "            for i in xrange(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:,i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i].\n",
    "                \n",
    "                feature = feature_matrix[:,i] \n",
    "                if len(feature)==1:\n",
    "                    feature_is_constant=True\n",
    "                else:\n",
    "                    feature_is_constant=False\n",
    "                if i==0:\n",
    "                    derivative=2*errors.sum()\n",
    "                else:                \n",
    "                    derivative = feature_derivative_ridge(errors, feature, weights, l2_penalty, feature_is_constant)\n",
    "            #(Remember: when i=0, you are computing the derivative of the constant!)\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "                weights[i]=weights[i]-step_size*derivative\n",
    "            \n",
    "            cost.append(ctemp)\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "            \n",
    "            \n",
    "    print 'Done with gradient descent at iteration ', iteration\n",
    "    print 'Learned weights = ', str(weights)\n",
    "    print cost\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing effect of L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 penalty gets its name because it causes weights to have small L2 norms than otherwise. Let's see how large weights get penalized. Let us consider a simple model with 1 feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the dataset into training set and test set. Make sure to use `seed=0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,test_data = sales.random_split(.8,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will only use `'sqft_living'` to predict `'price'`. Use the `get_numpy_data` function to get a Numpy versions of your data with only this feature, for both the `train_data` and the `test_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "(simple_test_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the parameters for our optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.array([0., 0.])\n",
    "print len(initial_weights)\n",
    "step_size = 1e-12\n",
    "max_iterations=1000\n",
    "l2_penalty=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider no regularization.  Set the `l2_penalty` to `0.0` and run your ridge regression algorithm to learn the weights of your model.  Call your weights:\n",
    "\n",
    "`simple_weights_0_penalty`\n",
    "\n",
    "we'll use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent with l2_penalty = 0\n",
      "Iteration = 1\n",
      "Cost function =  2.25318801037e+15\n",
      "Iteration = 2\n",
      "Cost function =  1.63637787619e+15\n",
      "Iteration = 3\n",
      "Cost function =  1.38366125697e+15\n",
      "Iteration = 4\n",
      "Cost function =  1.28011936278e+15\n",
      "Iteration = 5\n",
      "Cost function =  1.23769665275e+15\n",
      "Iteration = 6\n",
      "Cost function =  1.22031541452e+15\n",
      "Iteration = 7\n",
      "Cost function =  1.21319405328e+15\n",
      "Iteration = 8\n",
      "Cost function =  1.21027632176e+15\n",
      "Iteration = 9\n",
      "Cost function =  1.20908088215e+15\n",
      "Iteration = 10\n",
      "Cost function =  1.20859109207e+15\n",
      "Iteration = 20\n",
      "Cost function =  1.20825117435e+15\n",
      "Iteration = 30\n",
      "Cost function =  1.20825112831e+15\n",
      "Iteration = 40\n",
      "Cost function =  1.20825112759e+15\n",
      "Iteration = 50\n",
      "Cost function =  1.20825112686e+15\n",
      "Iteration = 60\n",
      "Cost function =  1.20825112614e+15\n",
      "Iteration = 70\n",
      "Cost function =  1.20825112542e+15\n",
      "Iteration = 80\n",
      "Cost function =  1.20825112469e+15\n",
      "Iteration = 90\n",
      "Cost function =  1.20825112397e+15\n",
      "Iteration = 100\n",
      "Cost function =  1.20825112325e+15\n",
      "Iteration = 200\n",
      "Cost function =  1.20825111602e+15\n",
      "Iteration = 300\n",
      "Cost function =  1.2082511088e+15\n",
      "Iteration = 400\n",
      "Cost function =  1.20825110157e+15\n",
      "Iteration = 500\n",
      "Cost function =  1.20825109434e+15\n",
      "Iteration = 600\n",
      "Cost function =  1.20825108712e+15\n",
      "Iteration = 700\n",
      "Cost function =  1.20825107989e+15\n",
      "Iteration = 800\n",
      "Cost function =  1.20825107267e+15\n",
      "Iteration = 900\n",
      "Cost function =  1.20825106544e+15\n",
      "Iteration = 1000\n",
      "Cost function =  1.20825105821e+15\n",
      "Done with gradient descent at iteration  1000\n",
      "Learned weights =  [ -2.16501618e-01   2.63024391e+02]\n",
      "[1e+50, 2253188010368869.0, 1636377876186573.5, 1383661256967049.0, 1280119362782798.0, 1237696652749973.5, 1220315414524471.5, 1213194053275130.5, 1210276321763526.2, 1209080882148115.0, 1208591092069118.7, 1208390417481720.2, 1208308197967510.5, 1208274511322593.0, 1208260709342286.5, 1208255054415563.0, 1208252737462267.2, 1208251788128134.5, 1208251399128653.0, 1208251239706914.2, 1208251174346716.0, 1208251147524980.0, 1208251136493046.5, 1208251131930438.0, 1208251130018412.2, 1208251129192370.7, 1208251128811274.0, 1208251128612477.5, 1208251128488372.5, 1208251128394869.7, 1208251128313905.2, 1208251128238077.7, 1208251128164355.2, 1208251128091495.0, 1208251128018988.0, 1208251127946625.5, 1208251127874322.7, 1208251127802044.0, 1208251127729775.5, 1208251127657511.0, 1208251127585247.7, 1208251127512985.7, 1208251127440723.7, 1208251127368462.0, 1208251127296200.0, 1208251127223938.5, 1208251127151676.5, 1208251127079415.0, 1208251127007153.0, 1208251126934891.2, 1208251126862629.5, 1208251126790368.0, 1208251126718106.0, 1208251126645844.2, 1208251126573582.5, 1208251126501320.5, 1208251126429059.0, 1208251126356797.2, 1208251126284535.5, 1208251126212274.0, 1208251126140012.0, 1208251126067750.0, 1208251125995488.5, 1208251125923227.0, 1208251125850965.0, 1208251125778703.5, 1208251125706441.5, 1208251125634179.7, 1208251125561918.0, 1208251125489656.5, 1208251125417394.7, 1208251125345132.7, 1208251125272871.0, 1208251125200609.5, 1208251125128347.5, 1208251125056086.0, 1208251124983824.0, 1208251124911562.5, 1208251124839300.7, 1208251124767039.0, 1208251124694777.2, 1208251124622515.5, 1208251124550253.7, 1208251124477992.2, 1208251124405730.5, 1208251124333468.5, 1208251124261207.0, 1208251124188945.0, 1208251124116683.5, 1208251124044421.7, 1208251123972160.0, 1208251123899898.2, 1208251123827636.5, 1208251123755375.0, 1208251123683113.0, 1208251123610851.5, 1208251123538589.5, 1208251123466328.0, 1208251123394066.5, 1208251123321804.5, 1208251123249542.7, 1208251123177281.0, 1208251123105019.5, 1208251123032757.7, 1208251122960496.0, 1208251122888234.2, 1208251122815972.5, 1208251122743710.7, 1208251122671449.0, 1208251122599187.5, 1208251122526925.5, 1208251122454664.0, 1208251122382402.5, 1208251122310140.5, 1208251122237879.0, 1208251122165617.2, 1208251122093355.5, 1208251122021093.7, 1208251121948832.2, 1208251121876570.5, 1208251121804308.7, 1208251121732047.0, 1208251121659785.2, 1208251121587523.5, 1208251121515262.0, 1208251121443000.0, 1208251121370738.5, 1208251121298476.7, 1208251121226215.0, 1208251121153953.5, 1208251121081692.0, 1208251121009430.0, 1208251120937168.2, 1208251120864906.7, 1208251120792645.0, 1208251120720383.5, 1208251120648121.5, 1208251120575860.0, 1208251120503598.2, 1208251120431336.5, 1208251120359075.0, 1208251120286813.0, 1208251120214551.5, 1208251120142289.7, 1208251120070028.2, 1208251119997766.7, 1208251119925504.7, 1208251119853243.5, 1208251119780981.5, 1208251119708720.0, 1208251119636458.2, 1208251119564196.5, 1208251119491935.0, 1208251119419673.2, 1208251119347411.5, 1208251119275150.0, 1208251119202888.2, 1208251119130626.5, 1208251119058365.0, 1208251118986103.0, 1208251118913841.5, 1208251118841579.7, 1208251118769318.2, 1208251118697056.5, 1208251118624794.7, 1208251118552533.2, 1208251118480271.5, 1208251118408010.0, 1208251118335748.0, 1208251118263486.5, 1208251118191225.0, 1208251118118963.2, 1208251118046701.5, 1208251117974440.0, 1208251117902178.2, 1208251117829916.5, 1208251117757655.0, 1208251117685393.5, 1208251117613131.5, 1208251117540870.0, 1208251117468608.5, 1208251117396346.7, 1208251117324085.0, 1208251117251823.5, 1208251117179561.7, 1208251117107300.0, 1208251117035038.5, 1208251116962776.7, 1208251116890515.2, 1208251116818253.5, 1208251116745992.0, 1208251116673730.5, 1208251116601468.5, 1208251116529207.0, 1208251116456945.5, 1208251116384683.7, 1208251116312422.0, 1208251116240160.5, 1208251116167899.0, 1208251116095637.0, 1208251116023375.5, 1208251115951114.0, 1208251115878852.5, 1208251115806590.5, 1208251115734329.0, 1208251115662067.5, 1208251115589806.0, 1208251115517544.2, 1208251115445282.5, 1208251115373021.0, 1208251115300759.5, 1208251115228497.5, 1208251115156236.0, 1208251115083974.5, 1208251115011712.7, 1208251114939451.2, 1208251114867189.5, 1208251114794928.0, 1208251114722666.2, 1208251114650405.0, 1208251114578143.2, 1208251114505881.5, 1208251114433620.0, 1208251114361358.2, 1208251114289096.7, 1208251114216835.0, 1208251114144573.5, 1208251114072312.0, 1208251114000050.2, 1208251113927788.7, 1208251113855527.0, 1208251113783265.5, 1208251113711003.7, 1208251113638742.2, 1208251113566480.5, 1208251113494219.0, 1208251113421957.5, 1208251113349695.7, 1208251113277434.2, 1208251113205172.7, 1208251113132911.0, 1208251113060649.5, 1208251112988388.0, 1208251112916126.2, 1208251112843864.7, 1208251112771603.0, 1208251112699341.2, 1208251112627080.0, 1208251112554818.2, 1208251112482556.5, 1208251112410295.0, 1208251112338033.5, 1208251112265772.0, 1208251112193510.5, 1208251112121248.7, 1208251112048987.0, 1208251111976725.5, 1208251111904463.7, 1208251111832202.2, 1208251111759941.0, 1208251111687679.2, 1208251111615417.7, 1208251111543156.0, 1208251111470894.5, 1208251111398633.0, 1208251111326371.5, 1208251111254109.7, 1208251111181848.3, 1208251111109586.7, 1208251111037325.0, 1208251110965063.5, 1208251110892802.0, 1208251110820540.5, 1208251110748278.5, 1208251110676017.0, 1208251110603755.5, 1208251110531494.0, 1208251110459232.5, 1208251110386971.0, 1208251110314709.5, 1208251110242447.7, 1208251110170186.2, 1208251110097924.5, 1208251110025663.0, 1208251109953401.5, 1208251109881140.0, 1208251109808878.2, 1208251109736617.0, 1208251109664355.2, 1208251109592094.0, 1208251109519832.0, 1208251109447570.7, 1208251109375309.0, 1208251109303047.5, 1208251109230785.7, 1208251109158524.5, 1208251109086263.0, 1208251109014001.2, 1208251108941739.7, 1208251108869478.2, 1208251108797216.5, 1208251108724955.0, 1208251108652693.5, 1208251108580432.0, 1208251108508170.5, 1208251108435909.0, 1208251108363647.2, 1208251108291385.7, 1208251108219124.2, 1208251108146862.7, 1208251108074601.2, 1208251108002339.5, 1208251107930078.0, 1208251107857816.5, 1208251107785555.0, 1208251107713293.5, 1208251107641032.0, 1208251107568770.5, 1208251107496508.7, 1208251107424247.5, 1208251107351986.0, 1208251107279724.5, 1208251107207463.0, 1208251107135201.2, 1208251107062939.7, 1208251106990678.0, 1208251106918416.5, 1208251106846155.0, 1208251106773893.5, 1208251106701632.0, 1208251106629370.5, 1208251106557109.0, 1208251106484847.5, 1208251106412586.0, 1208251106340324.5, 1208251106268062.7, 1208251106195801.5, 1208251106123540.0, 1208251106051278.5, 1208251105979017.0, 1208251105906755.5, 1208251105834493.7, 1208251105762232.5, 1208251105689971.0, 1208251105617709.2, 1208251105545448.0, 1208251105473186.0, 1208251105400924.7, 1208251105328663.2, 1208251105256401.7, 1208251105184140.2, 1208251105111878.7, 1208251105039617.0, 1208251104967355.7, 1208251104895094.2, 1208251104822832.7, 1208251104750571.5, 1208251104678309.5, 1208251104606048.0, 1208251104533786.5, 1208251104461525.0, 1208251104389263.7, 1208251104317002.0, 1208251104244740.5, 1208251104172479.2, 1208251104100217.7, 1208251104027956.2, 1208251103955694.7, 1208251103883433.0, 1208251103811171.7, 1208251103738910.2, 1208251103666648.5, 1208251103594387.2, 1208251103522126.0, 1208251103449864.5, 1208251103377603.0, 1208251103305341.5, 1208251103233080.0, 1208251103160818.0, 1208251103088557.0, 1208251103016295.5, 1208251102944034.0, 1208251102871772.5, 1208251102799511.0, 1208251102727249.5, 1208251102654988.0, 1208251102582726.5, 1208251102510465.0, 1208251102438203.7, 1208251102365942.0, 1208251102293680.5, 1208251102221419.2, 1208251102149157.7, 1208251102076896.0, 1208251102004634.7, 1208251101932373.0, 1208251101860111.5, 1208251101787850.2, 1208251101715589.0, 1208251101643327.5, 1208251101571066.0, 1208251101498804.2, 1208251101426543.0, 1208251101354281.5, 1208251101282020.0, 1208251101209758.5, 1208251101137497.0, 1208251101065235.5, 1208251100992974.0, 1208251100920713.0, 1208251100848451.5, 1208251100776190.0, 1208251100703928.2, 1208251100631667.0, 1208251100559405.5, 1208251100487144.0, 1208251100414882.5, 1208251100342621.0, 1208251100270359.5, 1208251100198098.0, 1208251100125836.7, 1208251100053575.2, 1208251099981314.0, 1208251099909052.2, 1208251099836791.0, 1208251099764529.7, 1208251099692268.0, 1208251099620006.5, 1208251099547745.2, 1208251099475483.7, 1208251099403222.2, 1208251099330960.7, 1208251099258699.5, 1208251099186438.0, 1208251099114176.5, 1208251099041915.0, 1208251098969653.5, 1208251098897392.2, 1208251098825131.0, 1208251098752869.2, 1208251098680608.0, 1208251098608346.5, 1208251098536085.0, 1208251098463823.5, 1208251098391562.2, 1208251098319300.7, 1208251098247039.5, 1208251098174778.0, 1208251098102516.5, 1208251098030255.0, 1208251097957993.5, 1208251097885732.0, 1208251097813470.7, 1208251097741209.5, 1208251097668948.0, 1208251097596686.5, 1208251097524425.0, 1208251097452163.7, 1208251097379902.2, 1208251097307641.0, 1208251097235379.5, 1208251097163118.0, 1208251097090856.5, 1208251097018595.2, 1208251096946333.7, 1208251096874072.2, 1208251096801811.0, 1208251096729549.5, 1208251096657288.0, 1208251096585026.5, 1208251096512765.2, 1208251096440504.0, 1208251096368242.5, 1208251096295981.2, 1208251096223719.7, 1208251096151458.5, 1208251096079197.0, 1208251096006935.5, 1208251095934674.0, 1208251095862412.5, 1208251095790151.2, 1208251095717890.0, 1208251095645628.5, 1208251095573367.0, 1208251095501105.7, 1208251095428844.5, 1208251095356583.0, 1208251095284321.5, 1208251095212060.0, 1208251095139798.7, 1208251095067537.2, 1208251094995275.7, 1208251094923014.5, 1208251094850753.0, 1208251094778491.7, 1208251094706230.5, 1208251094633969.0, 1208251094561707.5, 1208251094489446.2, 1208251094417185.0, 1208251094344923.5, 1208251094272662.0, 1208251094200400.5, 1208251094128139.5, 1208251094055878.0, 1208251093983616.5, 1208251093911355.0, 1208251093839093.7, 1208251093766832.5, 1208251093694571.0, 1208251093622309.5, 1208251093550048.2, 1208251093477787.0, 1208251093405525.5, 1208251093333264.0, 1208251093261002.5, 1208251093188741.2, 1208251093116480.0, 1208251093044218.5, 1208251092971957.2, 1208251092899696.0, 1208251092827434.5, 1208251092755173.0, 1208251092682911.7, 1208251092610650.5, 1208251092538389.0, 1208251092466127.7, 1208251092393866.5, 1208251092321605.0, 1208251092249343.7, 1208251092177082.2, 1208251092104821.0, 1208251092032559.5, 1208251091960298.5, 1208251091888037.0, 1208251091815775.5, 1208251091743514.0, 1208251091671253.0, 1208251091598991.5, 1208251091526730.0, 1208251091454468.7, 1208251091382207.5, 1208251091309946.0, 1208251091237684.5, 1208251091165423.5, 1208251091093162.0, 1208251091020900.5, 1208251090948639.2, 1208251090876378.0, 1208251090804116.5, 1208251090731855.5, 1208251090659594.0, 1208251090587332.5, 1208251090515071.2, 1208251090442810.0, 1208251090370548.5, 1208251090298287.5, 1208251090226025.7, 1208251090153764.5, 1208251090081503.0, 1208251090009242.0, 1208251089936980.5, 1208251089864719.5, 1208251089792458.0, 1208251089720196.5, 1208251089647935.5, 1208251089575674.0, 1208251089503412.5, 1208251089431151.5, 1208251089358890.0, 1208251089286628.5, 1208251089214367.0, 1208251089142106.0, 1208251089069844.7, 1208251088997583.5, 1208251088925322.0, 1208251088853060.7, 1208251088780799.5, 1208251088708538.0, 1208251088636276.7, 1208251088564015.5, 1208251088491754.0, 1208251088419492.7, 1208251088347231.5, 1208251088274970.0, 1208251088202709.0, 1208251088130447.5, 1208251088058186.0, 1208251087985924.7, 1208251087913663.7, 1208251087841402.2, 1208251087769141.0, 1208251087696879.7, 1208251087624618.2, 1208251087552357.0, 1208251087480095.7, 1208251087407834.5, 1208251087335573.0, 1208251087263311.7, 1208251087191050.5, 1208251087118789.0, 1208251087046528.0, 1208251086974266.5, 1208251086902005.2, 1208251086829744.0, 1208251086757482.7, 1208251086685221.5, 1208251086612960.0, 1208251086540698.7, 1208251086468437.5, 1208251086396176.2, 1208251086323915.0, 1208251086251653.5, 1208251086179392.5, 1208251086107131.0, 1208251086034869.7, 1208251085962608.5, 1208251085890347.2, 1208251085818086.0, 1208251085745824.5, 1208251085673563.0, 1208251085601302.2, 1208251085529040.7, 1208251085456779.5, 1208251085384518.2, 1208251085312256.7, 1208251085239995.5, 1208251085167734.5, 1208251085095473.2, 1208251085023212.0, 1208251084950950.5, 1208251084878689.2, 1208251084806428.0, 1208251084734167.0, 1208251084661905.5, 1208251084589644.0, 1208251084517383.0, 1208251084445121.5, 1208251084372860.2, 1208251084300599.0, 1208251084228338.0, 1208251084156076.7, 1208251084083815.0, 1208251084011554.0, 1208251083939292.7, 1208251083867031.5, 1208251083794770.2, 1208251083722509.0, 1208251083650247.5, 1208251083577986.5, 1208251083505725.2, 1208251083433464.0, 1208251083361202.5, 1208251083288941.5, 1208251083216680.2, 1208251083144419.0, 1208251083072157.5, 1208251082999896.5, 1208251082927635.2, 1208251082855374.0, 1208251082783112.7, 1208251082710851.2, 1208251082638590.0, 1208251082566329.0, 1208251082494067.7, 1208251082421806.2, 1208251082349545.0, 1208251082277284.0, 1208251082205022.5, 1208251082132761.5, 1208251082060500.2, 1208251081988239.0, 1208251081915977.5, 1208251081843716.5, 1208251081771455.2, 1208251081699194.0, 1208251081626932.7, 1208251081554671.2, 1208251081482410.0, 1208251081410149.0, 1208251081337887.5, 1208251081265626.5, 1208251081193365.5, 1208251081121104.0, 1208251081048843.0, 1208251080976581.5, 1208251080904320.5, 1208251080832059.2, 1208251080759798.0, 1208251080687537.0, 1208251080615275.5, 1208251080543014.2, 1208251080470753.0, 1208251080398491.7, 1208251080326230.5, 1208251080253969.5, 1208251080181708.0, 1208251080109446.7, 1208251080037185.5, 1208251079964924.5, 1208251079892663.2, 1208251079820402.0, 1208251079748141.0, 1208251079675879.5, 1208251079603618.2, 1208251079531357.5, 1208251079459096.0, 1208251079386834.7, 1208251079314573.5, 1208251079242312.2, 1208251079170051.0, 1208251079097789.7, 1208251079025528.5, 1208251078953267.5, 1208251078881006.0, 1208251078808745.0, 1208251078736484.0, 1208251078664222.5, 1208251078591961.5, 1208251078519700.0, 1208251078447439.0, 1208251078375177.7, 1208251078302916.5, 1208251078230655.5, 1208251078158394.2, 1208251078086133.0, 1208251078013871.7, 1208251077941610.5, 1208251077869349.5, 1208251077797088.0, 1208251077724827.0, 1208251077652565.7, 1208251077580304.5, 1208251077508043.5, 1208251077435782.2, 1208251077363521.0, 1208251077291260.0, 1208251077218998.5, 1208251077146737.5, 1208251077074476.2, 1208251077002215.0, 1208251076929954.0, 1208251076857692.7, 1208251076785431.5, 1208251076713170.2, 1208251076640909.2, 1208251076568648.0, 1208251076496387.0, 1208251076424125.5, 1208251076351864.5, 1208251076279603.2, 1208251076207342.2, 1208251076135081.0, 1208251076062819.7, 1208251075990558.5, 1208251075918297.5, 1208251075846036.0, 1208251075773775.0, 1208251075701514.0, 1208251075629252.7, 1208251075556991.5, 1208251075484730.5, 1208251075412469.2, 1208251075340208.0, 1208251075267947.0, 1208251075195685.7, 1208251075123424.5, 1208251075051163.5, 1208251074978902.2, 1208251074906641.0, 1208251074834380.0, 1208251074762118.7, 1208251074689857.5, 1208251074617596.5, 1208251074545335.2, 1208251074473074.2, 1208251074400813.0, 1208251074328552.0, 1208251074256290.7, 1208251074184029.5, 1208251074111768.5, 1208251074039507.2, 1208251073967246.0, 1208251073894984.7, 1208251073822723.7, 1208251073750462.5, 1208251073678201.5, 1208251073605940.5, 1208251073533679.0, 1208251073461418.0, 1208251073389157.0, 1208251073316895.7, 1208251073244634.5, 1208251073172373.5, 1208251073100112.5, 1208251073027851.2, 1208251072955590.0, 1208251072883328.7, 1208251072811067.7, 1208251072738806.5, 1208251072666545.5, 1208251072594284.5, 1208251072522023.0, 1208251072449762.0, 1208251072377501.0, 1208251072305239.7, 1208251072232978.7, 1208251072160717.5, 1208251072088456.5, 1208251072016195.0, 1208251071943934.0, 1208251071871673.0, 1208251071799412.0, 1208251071727150.5, 1208251071654889.5, 1208251071582628.5, 1208251071510367.5, 1208251071438106.2, 1208251071365845.0, 1208251071293584.0, 1208251071221323.0, 1208251071149061.7, 1208251071076800.5, 1208251071004539.5, 1208251070932278.5, 1208251070860017.2, 1208251070787756.2, 1208251070715495.0, 1208251070643234.2, 1208251070570972.7, 1208251070498711.7, 1208251070426450.7, 1208251070354189.5, 1208251070281928.5, 1208251070209667.2, 1208251070137406.2, 1208251070065145.0, 1208251069992884.0, 1208251069920622.7, 1208251069848361.7, 1208251069776100.7, 1208251069703839.5, 1208251069631578.5, 1208251069559317.5, 1208251069487056.5, 1208251069414795.2, 1208251069342534.0, 1208251069270273.0, 1208251069198012.0, 1208251069125751.0, 1208251069053489.7, 1208251068981228.5, 1208251068908967.7, 1208251068836706.5, 1208251068764445.5, 1208251068692184.2, 1208251068619923.2, 1208251068547662.0, 1208251068475401.0, 1208251068403139.7, 1208251068330878.7, 1208251068258618.0, 1208251068186356.5, 1208251068114095.5, 1208251068041834.5, 1208251067969573.2, 1208251067897312.5, 1208251067825051.2, 1208251067752790.0, 1208251067680529.0, 1208251067608268.0, 1208251067536007.0, 1208251067463746.0, 1208251067391484.5, 1208251067319223.5, 1208251067246962.7, 1208251067174701.5, 1208251067102440.5, 1208251067030179.2, 1208251066957918.5, 1208251066885657.5, 1208251066813396.2, 1208251066741135.2, 1208251066668874.0, 1208251066596613.0, 1208251066524352.0, 1208251066452091.0, 1208251066379829.7, 1208251066307568.7, 1208251066235307.7, 1208251066163046.5, 1208251066090785.5, 1208251066018524.2, 1208251065946263.5, 1208251065874002.5, 1208251065801741.2, 1208251065729480.2, 1208251065657219.0, 1208251065584958.0, 1208251065512697.0, 1208251065440436.0, 1208251065368175.0, 1208251065295914.0, 1208251065223652.7, 1208251065151391.7, 1208251065079130.7, 1208251065006869.7, 1208251064934608.5, 1208251064862347.5, 1208251064790086.5, 1208251064717825.5, 1208251064645564.5, 1208251064573303.5, 1208251064501042.5, 1208251064428781.2, 1208251064356520.2, 1208251064284259.2, 1208251064211998.0, 1208251064139737.2, 1208251064067476.5, 1208251063995215.0, 1208251063922954.0, 1208251063850693.0, 1208251063778432.0, 1208251063706171.0, 1208251063633910.0, 1208251063561649.0, 1208251063489387.7, 1208251063417126.7, 1208251063344865.7, 1208251063272605.0, 1208251063200343.5, 1208251063128082.5, 1208251063055821.7, 1208251062983560.5, 1208251062911299.5, 1208251062839038.5, 1208251062766777.5, 1208251062694516.5, 1208251062622255.5, 1208251062549994.5, 1208251062477733.5, 1208251062405472.5, 1208251062333211.5, 1208251062260950.5, 1208251062188689.5, 1208251062116428.5, 1208251062044167.2, 1208251061971906.5, 1208251061899645.5, 1208251061827384.5, 1208251061755123.2, 1208251061682862.5, 1208251061610601.5, 1208251061538340.5, 1208251061466079.2, 1208251061393818.2, 1208251061321557.0, 1208251061249296.2, 1208251061177035.2, 1208251061104774.2, 1208251061032513.5, 1208251060960252.2, 1208251060887991.2, 1208251060815730.0, 1208251060743469.2, 1208251060671208.2, 1208251060598947.2, 1208251060526686.5, 1208251060454425.2, 1208251060382164.2, 1208251060309903.0, 1208251060237642.0, 1208251060165381.2, 1208251060093120.0, 1208251060020859.0, 1208251059948598.2, 1208251059876337.2, 1208251059804076.5, 1208251059731815.5, 1208251059659554.0, 1208251059587293.5, 1208251059515032.5, 1208251059442771.5, 1208251059370510.2, 1208251059298249.5, 1208251059225988.2, 1208251059153727.5, 1208251059081466.5, 1208251059009205.5, 1208251058936944.5, 1208251058864683.5, 1208251058792422.5, 1208251058720161.5, 1208251058647900.5, 1208251058575639.5, 1208251058503378.5, 1208251058431117.7, 1208251058358856.5, 1208251058286595.5, 1208251058214334.7]\n"
     ]
    }
   ],
   "source": [
    "simple_weights_0_penalty=ridge_regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, l2_penalty, max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's consider high regularization.  Set the `l2_penalty` to `1e11` and run your ridge regression algorithm to learn the weights of your model.  Call your weights:\n",
    "\n",
    "`simple_weights_high_penalty`\n",
    "\n",
    "we'll use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Starting gradient descent with l2_penalty = 1e+11\n",
      "Iteration = 1\n",
      "Cost function =  7.43305185103e+15\n",
      "Iteration = 2\n",
      "Cost function =  4.65487992621e+15\n",
      "Iteration = 3\n",
      "Cost function =  4.49468510438e+15\n",
      "Iteration = 4\n",
      "Cost function =  4.48542815495e+15\n",
      "Iteration = 5\n",
      "Cost function =  4.48488697985e+15\n",
      "Iteration = 6\n",
      "Cost function =  4.48485346654e+15\n",
      "Iteration = 7\n",
      "Cost function =  4.48485084644e+15\n",
      "Iteration = 8\n",
      "Cost function =  4.48485049097e+15\n",
      "Iteration = 9\n",
      "Cost function =  4.48485040979e+15\n",
      "Iteration = 10\n",
      "Cost function =  4.48485039099e+15\n",
      "Done with gradient descent at iteration  11\n",
      "Learned weights =  [  1.09311751e-01   1.24518014e+02]\n",
      "[1e+50, 7433051851026171.0, 4654879926212546.0, 4494685104382835.0, 4485428154945341.0, 4484886979849796.0, 4484853466541878.5, 4484850846435538.0, 4484850490965896.0, 4484850409787939.0, 4484850390994695.0]\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.array([0., 0.])\n",
    "print len(initial_weights)\n",
    "step_size = 1e-12\n",
    "max_iterations=1000\n",
    "l2_penalty_h=1e11\n",
    "simple_weights_high_penalty=ridge_regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, l2_penalty_h, max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will plot the two learned models.  (The blue line is for the model with no regularization and the red line is for the one with high regularization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2f7e8358>,\n",
       " <matplotlib.lines.Line2D at 0x2f7e8438>,\n",
       " <matplotlib.lines.Line2D at 0x2f7e85c0>,\n",
       " <matplotlib.lines.Line2D at 0x2f7f5048>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEACAYAAABoJ6s/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGyY6hmEYRt74/wFVxaeMMYbSPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f21c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(simple_feature_matrix,output,'k.',\n",
    "         simple_feature_matrix,predict_output(simple_feature_matrix, simple_weights_0_penalty),'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2fba5400>,\n",
       " <matplotlib.lines.Line2D at 0x2fba54e0>,\n",
       " <matplotlib.lines.Line2D at 0x2fba5668>,\n",
       " <matplotlib.lines.Line2D at 0x2fbb20f0>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEACAYAAABoJ6s/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOoZhGEbe+P8BCQSnjAYH0QcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2fa7a320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(simple_feature_matrix,output,'k.',simple_feature_matrix,predict_output(simple_feature_matrix, simple_weights_high_penalty),'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS on the TEST data for the following three sets of weights:\n",
    "1. The initial weights (all zeros)\n",
    "2. The weights learned with no regularization\n",
    "3. The weights learned with high regularization\n",
    "\n",
    "Which weights perform best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "1.78427328252e+15\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.array([0., 0.])\n",
    "predictions1=predict_output(simple_test_feature_matrix,initial_weights)\n",
    "print predictions1\n",
    "errors = (predictions1 -test_output)**2\n",
    "print errors.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.15963990e-01   2.63024390e+02]\n",
      "[ 376124.66237345  775921.73585101  449771.49169827 ...,  662821.24795933\n",
      "  607586.12596572  268284.66229069]\n",
      "2.75723632555e+14\n"
     ]
    }
   ],
   "source": [
    "predictions2=predict_output(simple_test_feature_matrix,simple_weights_0_penalty)\n",
    "print simple_weights_0_penalty\n",
    "print predictions2\n",
    "errors2 = (predictions2 -test_output)**2\n",
    "print errors2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.09311751e-01   1.24518014e+02]\n",
      "[ 178060.86920074  367328.25034148  212925.91309509 ...,  313785.50436088\n",
      "  287636.72144012  127008.4834983 ]\n",
      "6.94992355694e+14\n"
     ]
    }
   ],
   "source": [
    "predictions3=predict_output(simple_test_feature_matrix,simple_weights_high_penalty)\n",
    "print simple_weights_high_penalty\n",
    "print predictions3\n",
    "errors3 = (predictions3 -test_output)**2\n",
    "print errors3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What is the value of the coefficient for `sqft_living` that you learned with no regularization, rounded to 1 decimal place?  What about the one with high regularization?\n",
    "2. Comparing the lines you fit with the with no regularization versus high regularization, which one is steeper?\n",
    "3. What are the RSS on the test data for each of the set of weights above (initial, no regularization, high regularization)? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multiple regression with L2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now consider a model with 2 features: `['sqft_living', 'sqft_living15']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create Numpy versions of your training and test data with these two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to re-inialize the weights, since we have one extra parameter. Let us also set the step size and maximum number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_weights = np.array([0.0,0.0,0.0])\n",
    "step_size = 1e-12\n",
    "max_iterations = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's consider no regularization.  Set the `l2_penalty` to `0.0` and run your ridge regression algorithm to learn the weights of your model.  Call your weights:\n",
    "\n",
    "`multiple_weights_0_penalty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent with l2_penalty = 0.0\n",
      "Iteration = 1\n",
      "Cost function =  7.43305185103e+15\n",
      "Iteration = 2\n",
      "Cost function =  1.27060580122e+15\n",
      "Iteration = 3\n",
      "Cost function =  1.26651782148e+15\n",
      "Iteration = 4\n",
      "Cost function =  1.26436880349e+15\n",
      "Iteration = 5\n",
      "Cost function =  1.26229612955e+15\n",
      "Iteration = 6\n",
      "Cost function =  1.26029656476e+15\n",
      "Iteration = 7\n",
      "Cost function =  1.25836753019e+15\n",
      "Iteration = 8\n",
      "Cost function =  1.25650653805e+15\n",
      "Iteration = 9\n",
      "Cost function =  1.2547111883e+15\n",
      "Iteration = 10\n",
      "Cost function =  1.25297916553e+15\n",
      "Iteration = 20\n",
      "Cost function =  1.23868739166e+15\n",
      "Iteration = 30\n",
      "Cost function =  1.22870737118e+15\n",
      "Iteration = 40\n",
      "Cost function =  1.22173827054e+15\n",
      "Iteration = 50\n",
      "Cost function =  1.21687171089e+15\n",
      "Iteration = 60\n",
      "Cost function =  1.21347336654e+15\n",
      "Iteration = 70\n",
      "Cost function =  1.21110028459e+15\n",
      "Iteration = 80\n",
      "Cost function =  1.20944314869e+15\n",
      "Iteration = 90\n",
      "Cost function =  1.20828596166e+15\n",
      "Iteration = 100\n",
      "Cost function =  1.20747789152e+15\n",
      "Iteration = 200\n",
      "Cost function =  1.20565908304e+15\n",
      "Iteration = 300\n",
      "Cost function =  1.20560892322e+15\n",
      "Iteration = 400\n",
      "Cost function =  1.20560752683e+15\n",
      "Iteration = 500\n",
      "Cost function =  1.2056074749e+15\n",
      "Iteration = 600\n",
      "Cost function =  1.20560746004e+15\n",
      "Iteration = 700\n",
      "Cost function =  1.2056074462e+15\n",
      "Iteration = 800\n",
      "Cost function =  1.20560743239e+15\n",
      "Iteration = 900\n",
      "Cost function =  1.20560741858e+15\n",
      "Iteration = 1000\n",
      "Cost function =  1.20560740477e+15\n",
      "Done with gradient descent at iteration  1000\n",
      "Learned weights =  [  -0.36692953  243.31658446   22.129868  ]\n",
      "[1e+50, 7433051851026171.0, 1270605801217067.7, 1266517821483066.0, 1264368803488043.2, 1262296129546437.2, 1260296564756940.0, 1258367530192017.5, 1256506538053802.0, 1254711188296048.7, 1252979165528842.0, 1251308236032526.2, 1249696244876972.5, 1248141113142450.0, 1246640835238527.2, 1245193476317543.5, 1243797169779313.7, 1242450114863850.0, 1241150574328993.0, 1239896872209962.0, 1238687391657930.7, 1237520572854842.5, 1236394911001775.0, 1235308954378263.5, 1234261302470074.0, 1233250604163018.0, 1232275556000473.7, 1231334900502371.7, 1230427424543473.7, 1229551957788852.5, 1228707371184560.0, 1227892575501531.0, 1227106519930848.5, 1226348190728558.5, 1225616609908284.0, 1224910833979957.5, 1224229952733037.5, 1223573088062649.0, 1222939392837125.7, 1222328049805498.0, 1221738270543520.5, 1221169294436868.5, 1220620387700208.2, 1220090842430861.5, 1219579975695853.0, 1219087128651159.2, 1218611665692023.2, 1218152973633241.5, 1217710460918364.0, 1217283556856786.5, 1216871710887755.7, 1216474391870331.5, 1216091087398396.7, 1215721303139828.5, 1215364562198976.5, 1215020404501630.5, 1214688386201682.2, 1214368079108713.5, 1214059070135777.0, 1213760960766655.0, 1213473366541907.7, 1213195916563053.7, 1212928253014235.5, 1212670030700759.0, 1212420916603910.5, 1212180589451475.2, 1211948739303406.2, 1211725067152106.5, 1211509284536811.7, 1211301113171572.5, 1211100284586363.0, 1210906539780843.0, 1210719628890337.2, 1210539310863595.5, 1210365353151916.5, 1210197531409241.0, 1210035629202822.5, 1209879437734099.0, 1209728755569418.7, 1209583388380255.0, 1209443148692592.0, 1209307855645144.0, 1209177334756108.5, 1209051417698143.5, 1208929942081280.5, 1208812751243499.5, 1208699694048687.0, 1208590624691721.0, 1208485402510434.0, 1208383891804205.5, 1208285961658953.7, 1208191485778302.5, 1208100342320701.5, 1208012413742291.0, 1207927586645312.0, 1207845751631860.2, 1207766803162801.5, 1207690639421660.5, 1207617162183313.7, 1207546276687311.5, 1207477891515669.7, 1207411918474972.0, 1207348272482629.0, 1207286871457152.7, 1207227636212297.5, 1207170490354937.7, 1207115360186547.0, 1207062174608150.2, 1207010865028633.5, 1206961365276280.7, 1206913611513439.0, 1206867542154186.0, 1206823097784907.0, 1206780221087672.2, 1206738856766314.0, 1206698951475115.2, 1206660453750011.5, 1206623313942219.0, 1206587484154205.2, 1206552918177917.0, 1206519571435189.0, 1206487400920251.5, 1206456365144267.7, 1206426424081829.5, 1206397539119334.5, 1206369673005192.0, 1206342789801777.5, 1206316854839086.5, 1206291834670023.5, 1206267697027264.5, 1206244410781644.0, 1206221945902010.0, 1206200273416492.0, 1206179365375138.5, 1206159194813870.5, 1206139735719708.2, 1206120962997221.0, 1206102852436166.0, 1206085380680260.5, 1206068525197065.0, 1206052264248922.0, 1206036576864920.5, 1206021442813853.0, 1206006842578123.5, 1205992757328575.0, 1205979168900208.0, 1205966059768753.5, 1205953413028072.0, 1205941212368350.5, 1205929442055069.0, 1205918086908707.5, 1205907132285171.0, 1205896564056901.2, 1205886368594659.5, 1205876532749947.5, 1205867043838051.7, 1205857889621683.7, 1205849058295198.2, 1205840538469368.5, 1205832319156696.7, 1205824389757245.5, 1205816740044967.0, 1205809360154513.5, 1205802240568517.5, 1205795372105313.0, 1205788745907099.5, 1205782353428514.5, 1205776186425615.0, 1205770236945243.5, 1205764497314774.0, 1205758960132215.0, 1205753618256664.0, 1205748464799097.5, 1205743493113487.5, 1205738696788230.0, 1205734069637876.0, 1205729605695155.0, 1205725299203277.7, 1205721144608514.0, 1205717136553029.0, 1205713269867973.0, 1205709539566816.7, 1205705940838919.5, 1205702469043325.2, 1205699119702778.0, 1205695888497945.5, 1205692771261852.7, 1205689763974503.0, 1205686862757698.5, 1205684063870034.2, 1205681363702076.5, 1205678758771705.7, 1205676245719626.2, 1205673821305034.2, 1205671482401438.5, 1205669225992627.5, 1205667049168780.0, 1205664949122712.2, 1205662923146258.0, 1205660968626775.0, 1205659083043776.5, 1205657263965680.3, 1205655509046673.2, 1205653816023685.0, 1205652182713470.0, 1205650607009793.0, 1205649086880709.5, 1205647620365949.5, 1205646205574385.5, 1205644840681596.7, 1205643523927513.7, 1205642253614150.0, 1205641028103412.0, 1205639845814986.0, 1205638705224300.7, 1205637604860560.0, 1205636543304847.7, 1205635519188296.0, 1205634531190321.5, 1205633578036921.0, 1205632658499029.5, 1205631771390934.0, 1205630915568745.0, 1205630089928921.2, 1205629293406846.7, 1205628524975457.0, 1205627783643915.5, 1205627068456334.7, 1205626378490544.5, 1205625712856901.5, 1205625070697143.0, 1205624451183280.0, 1205623853516528.2, 1205623276926279.5, 1205622720669106.0, 1205622184027804.5, 1205621666310467.5, 1205621166849594.5, 1205620685001228.7, 1205620220144128.5, 1205619771678963.5, 1205619339027545.5, 1205618921632079.0, 1205618518954444.0, 1205618130475501.5, 1205617755694424.3, 1205617394128050.0, 1205617045310259.5, 1205616708791374.5, 1205616384137578.2, 1205616070930356.2, 1205615768765955.7, 1205615477254865.5, 1205615196021313.5, 1205614924702782.7, 1205614662949542.2, 1205614410424197.7, 1205614166801255.5, 1205613931766703.0, 1205613705017603.7, 1205613486261707.0, 1205613275217070.0, 1205613071611694.5, 1205612875183177.7, 1205612685678371.7, 1205612502853058.0, 1205612326471631.7, 1205612156306799.5, 1205611992139284.5, 1205611833757544.7, 1205611680957499.5, 1205611533542267.0, 1205611391321910.0, 1205611254113190.5, 1205611121739334.5, 1205610994029802.5, 1205610870820070.5, 1205610751951419.0, 1205610637270725.0, 1205610526630267.7, 1205610419887537.0, 1205610316905049.2, 1205610217550170.0, 1205610121694943.0, 1205610029215926.5, 1205609939994031.5, 1205609853914371.0, 1205609770866108.5, 1205609690742319.0, 1205609613439848.0, 1205609538859179.7, 1205609466904308.5, 1205609397482615.0, 1205609330504747.5, 1205609265884504.7, 1205609203538727.5, 1205609143387188.2, 1205609085352490.5, 1205609029359967.5, 1205608975337585.5, 1205608923215852.5, 1205608872927727.5, 1205608824408534.0, 1205608777595876.2, 1205608732429560.2, 1205608688851515.5, 1205608646805718.7, 1205608606238123.0, 1205608567096588.5, 1205608529330814.5, 1205608492892273.0, 1205608457734149.5, 1205608423811280.0, 1205608391080093.5, 1205608359498556.2, 1205608329026116.5, 1205608299623653.7, 1205608271253426.5, 1205608243879025.5, 1205608217465324.7, 1205608191978437.5, 1205608167385673.0, 1205608143655492.5, 1205608120757470.5, 1205608098662254.5, 1205608077341527.5, 1205608056767970.5, 1205608036915229.2, 1205608017757878.2, 1205607999271389.5, 1205607981432099.5, 1205607964217180.0, 1205607947604607.5, 1205607931573135.5, 1205607916102267.0, 1205607901172228.5, 1205607886763942.5, 1205607872859005.7, 1205607859439664.0, 1205607846488788.5, 1205607833989855.5, 1205607821926923.5, 1205607810284613.2, 1205607799048089.0, 1205607788203037.0, 1205607777735649.0, 1205607767632604.0, 1205607757881050.5, 1205607748468590.0, 1205607739383262.2, 1205607730613528.2, 1205607722148256.0, 1205607713976706.2, 1205607706088519.0, 1205607698473698.5, 1205607691122603.0, 1205607684025929.7, 1205607677174705.0, 1205607670560271.0, 1205607664174275.5, 1205607658008660.5, 1205607652055652.5, 1205607646307753.0, 1205607640757726.5, 1205607635398593.5, 1205607630223621.5, 1205607625226313.5, 1205607620400403.5, 1205607615739845.7, 1205607611238807.7, 1205607606891662.5, 1205607602692982.0, 1205607598637530.0, 1205607594720253.5, 1205607590936279.0, 1205607587280904.7, 1205607583749594.7, 1205607580337972.7, 1205607577041816.7, 1205607573857054.5, 1205607570779756.5, 1205607567806132.0, 1205607564932524.5, 1205607562155405.7, 1205607559471372.5, 1205607556877142.0, 1205607554369545.5, 1205607551945528.0, 1205607549602141.0, 1205607547336540.7, 1205607545145983.5, 1205607543027822.0, 1205607540979503.0, 1205607538998562.5, 1205607537082624.0, 1205607535229395.0, 1205607533436663.5, 1205607531702295.5, 1205607530024232.2, 1205607528400487.5, 1205607526829146.0, 1205607525308358.5, 1205607523836342.7, 1205607522411377.5, 1205607521031804.0, 1205607519696020.5, 1205607518402482.5, 1205607517149700.2, 1205607515936236.0, 1205607514760702.5, 1205607513621762.2, 1205607512518124.5, 1205607511448544.0, 1205607510411819.5, 1205607509406791.7, 1205607508432343.2, 1205607507487395.0, 1205607506570906.5, 1205607505681874.0, 1205607504819329.0, 1205607503982337.0, 1205607503169997.0, 1205607502381439.2, 1205607501615825.0, 1205607500872345.0, 1205607500150218.5, 1205607499448692.0, 1205607498767039.2, 1205607498104559.0, 1205607497460575.5, 1205607496834435.5, 1205607496225510.5, 1205607495633192.2, 1205607495056895.5, 1205607494496056.0, 1205607493950126.7, 1205607493418583.2, 1205607492900917.7, 1205607492396640.2, 1205607491905279.0, 1205607491426378.0, 1205607490959498.5, 1205607490504215.5, 1205607490060120.7, 1205607489626819.0, 1205607489203930.0, 1205607488791086.5, 1205607488387933.7, 1205607487994130.0, 1205607487609346.0, 1205607487233263.2, 1205607486865574.5, 1205607486505984.0, 1205607486154206.2, 1205607485809965.5, 1205607485472995.7, 1205607485143041.0, 1205607484819853.5, 1205607484503194.0, 1205607484192833.2, 1205607483888548.5, 1205607483590125.5, 1205607483297357.5, 1205607483010045.2, 1205607482727996.0, 1205607482451024.5, 1205607482178951.5, 1205607481911603.5, 1205607481648814.5, 1205607481390424.0, 1205607481136276.5, 1205607480886222.0, 1205607480640116.7, 1205607480397821.0, 1205607480159200.5, 1205607479924125.7, 1205607479692471.5, 1205607479464117.0, 1205607479238946.2, 1205607479016847.0, 1205607478797710.0, 1205607478581431.7, 1205607478367911.0, 1205607478157050.7, 1205607477948756.5, 1205607477742938.7, 1205607477539509.5, 1205607477338384.5, 1205607477139482.5, 1205607476942725.0, 1205607476748036.7, 1205607476555344.5, 1205607476364577.7, 1205607476175668.7, 1205607475988552.0, 1205607475803164.2, 1205607475619444.5, 1205607475437333.7, 1205607475256775.5, 1205607475077715.0, 1205607474900098.7, 1205607474723876.7, 1205607474548999.2, 1205607474375419.0, 1205607474203090.5, 1205607474031969.2, 1205607473862012.5, 1205607473693179.7, 1205607473525431.0, 1205607473358728.0, 1205607473193033.5, 1205607473028313.0, 1205607472864531.0, 1205607472701655.0, 1205607472539653.0, 1205607472378494.0, 1205607472218148.5, 1205607472058587.5, 1205607471899783.7, 1205607471741710.0, 1205607471584341.0, 1205607471427651.5, 1205607471271618.0, 1205607471116216.5, 1205607470961425.7, 1205607470807223.5, 1205607470653589.5, 1205607470500503.2, 1205607470347945.7, 1205607470195897.7, 1205607470044342.2, 1205607469893261.0, 1205607469742638.0, 1205607469592456.5, 1205607469442701.0, 1205607469293357.0, 1205607469144409.2, 1205607468995844.5, 1205607468847648.5, 1205607468699809.0, 1205607468552313.0, 1205607468405148.0, 1205607468258303.0, 1205607468111766.5, 1205607467965527.7, 1205607467819575.7, 1205607467673901.0, 1205607467528493.2, 1205607467383343.5, 1205607467238442.0, 1205607467093780.7, 1205607466949350.7, 1205607466805144.2, 1205607466661152.7, 1205607466517369.5, 1205607466373786.5, 1205607466230397.0, 1205607466087194.0, 1205607465944171.0, 1205607465801322.0, 1205607465658640.0, 1205607465516119.7, 1205607465373755.5, 1205607465231541.7, 1205607465089473.0, 1205607464947544.2, 1205607464805750.5, 1205607464664087.0, 1205607464522549.5, 1205607464381133.0, 1205607464239833.5, 1205607464098647.0, 1205607463957569.2, 1205607463816596.5, 1205607463675725.2, 1205607463534951.7, 1205607463394272.5, 1205607463253684.0, 1205607463113183.5, 1205607462972767.7, 1205607462832433.5, 1205607462692178.2, 1205607462551998.7, 1205607462411893.0, 1205607462271857.5, 1205607462131890.7, 1205607461991989.5, 1205607461852152.3, 1205607461712376.0, 1205607461572659.0, 1205607461432998.7, 1205607461293393.7, 1205607461153841.7, 1205607461014341.0, 1205607460874889.7, 1205607460735486.0, 1205607460596128.2, 1205607460456815.0, 1205607460317544.5, 1205607460178315.5, 1205607460039126.0, 1205607459899975.2, 1205607459760861.0, 1205607459621783.0, 1205607459482739.5, 1205607459343729.0, 1205607459204751.0, 1205607459065804.0, 1205607458926886.5, 1205607458787998.0, 1205607458649137.5, 1205607458510303.5, 1205607458371495.5, 1205607458232712.7, 1205607458093953.7, 1205607457955218.5, 1205607457816505.0, 1205607457677813.5, 1205607457539143.0, 1205607457400492.2, 1205607457261861.0, 1205607457123248.7, 1205607456984654.5, 1205607456846077.7, 1205607456707517.5, 1205607456568974.0, 1205607456430445.7, 1205607456291932.5, 1205607456153434.0, 1205607456014949.7, 1205607455876479.0, 1205607455738021.0, 1205607455599576.0, 1205607455461143.5, 1205607455322722.0, 1205607455184312.0, 1205607455045913.5, 1205607454907525.0, 1205607454769146.7, 1205607454630778.5, 1205607454492419.5, 1205607454354069.7, 1205607454215728.5, 1205607454077396.5, 1205607453939072.0, 1205607453800755.7, 1205607453662447.0, 1205607453524145.7, 1205607453385851.5, 1205607453247564.2, 1205607453109283.5, 1205607452971009.0, 1205607452832741.2, 1205607452694479.0, 1205607452556222.5, 1205607452417971.2, 1205607452279725.5, 1205607452141485.0, 1205607452003249.7, 1205607451865019.0, 1205607451726793.0, 1205607451588571.0, 1205607451450353.7, 1205607451312140.5, 1205607451173931.2, 1205607451035726.0, 1205607450897524.2, 1205607450759326.0, 1205607450621131.5, 1205607450482940.2, 1205607450344752.5, 1205607450206567.5, 1205607450068385.5, 1205607449930206.5, 1205607449792030.2, 1205607449653857.0, 1205607449515685.7, 1205607449377517.5, 1205607449239351.5, 1205607449101188.0, 1205607448963026.5, 1205607448824867.2, 1205607448686710.2, 1205607448548555.2, 1205607448410402.0, 1205607448272250.5, 1205607448134101.2, 1205607447995953.5, 1205607447857807.7, 1205607447719663.0, 1205607447581520.5, 1205607447443379.0, 1205607447305239.5, 1205607447167101.0, 1205607447028963.7, 1205607446890828.0, 1205607446752693.7, 1205607446614560.5, 1205607446476428.5, 1205607446338297.5, 1205607446200168.0, 1205607446062039.0, 1205607445923911.5, 1205607445785784.5, 1205607445647658.7, 1205607445509534.0, 1205607445371410.0, 1205607445233287.0, 1205607445095164.5, 1205607444957043.0, 1205607444818922.2, 1205607444680802.5, 1205607444542683.0, 1205607444404564.2, 1205607444266446.5, 1205607444128329.2, 1205607443990212.7, 1205607443852096.5, 1205607443713981.0, 1205607443575866.0, 1205607443437752.0, 1205607443299638.0, 1205607443161524.5, 1205607443023411.5, 1205607442885299.0, 1205607442747187.0, 1205607442609075.5, 1205607442470964.5, 1205607442332853.7, 1205607442194743.5, 1205607442056633.5, 1205607441918524.0, 1205607441780414.7, 1205607441642305.5, 1205607441504197.0, 1205607441366088.7, 1205607441227980.7, 1205607441089873.0, 1205607440951766.0, 1205607440813658.7, 1205607440675551.5, 1205607440537445.0, 1205607440399338.7, 1205607440261232.5, 1205607440123126.5, 1205607439985020.7, 1205607439846915.5, 1205607439708810.2, 1205607439570705.2, 1205607439432600.2, 1205607439294495.7, 1205607439156391.0, 1205607439018286.5, 1205607438880182.7, 1205607438742078.5, 1205607438603974.5, 1205607438465871.0, 1205607438327767.2, 1205607438189664.0, 1205607438051560.5, 1205607437913457.5, 1205607437775354.5, 1205607437637251.2, 1205607437499148.5, 1205607437361046.0, 1205607437222943.2, 1205607437084840.5, 1205607436946738.5, 1205607436808636.0, 1205607436670533.7, 1205607436532431.5, 1205607436394329.5, 1205607436256227.5, 1205607436118125.7, 1205607435980024.0, 1205607435841922.5, 1205607435703820.5, 1205607435565719.0, 1205607435427617.5, 1205607435289516.0, 1205607435151414.5, 1205607435013313.5, 1205607434875212.0, 1205607434737110.7, 1205607434599009.5, 1205607434460908.5, 1205607434322807.7, 1205607434184706.5, 1205607434046605.5, 1205607433908504.7, 1205607433770404.0, 1205607433632303.2, 1205607433494202.5, 1205607433356101.5, 1205607433218001.0, 1205607433079900.2, 1205607432941799.5, 1205607432803699.0, 1205607432665598.5, 1205607432527498.0, 1205607432389397.5, 1205607432251297.0, 1205607432113196.5, 1205607431975096.0, 1205607431836995.7, 1205607431698895.5, 1205607431560795.0, 1205607431422695.0, 1205607431284594.5, 1205607431146494.2, 1205607431008394.0, 1205607430870294.0, 1205607430732193.5, 1205607430594093.5, 1205607430455993.2, 1205607430317893.2, 1205607430179793.0, 1205607430041693.0, 1205607429903593.0, 1205607429765492.7, 1205607429627392.7, 1205607429489292.7, 1205607429351192.7, 1205607429213092.5, 1205607429074993.0, 1205607428936892.7, 1205607428798792.7, 1205607428660693.0, 1205607428522593.0, 1205607428384493.0, 1205607428246393.0, 1205607428108293.0, 1205607427970193.2, 1205607427832093.5, 1205607427693993.5, 1205607427555893.5, 1205607427417794.0, 1205607427279694.0, 1205607427141594.0, 1205607427003494.5, 1205607426865394.5, 1205607426727294.7, 1205607426589195.0, 1205607426451095.0, 1205607426312995.2, 1205607426174895.5, 1205607426036795.5, 1205607425898696.0, 1205607425760596.0, 1205607425622496.5, 1205607425484396.5, 1205607425346297.0, 1205607425208197.2, 1205607425070097.5, 1205607424931997.5, 1205607424793898.0, 1205607424655798.5, 1205607424517698.5, 1205607424379598.7, 1205607424241499.0, 1205607424103399.2, 1205607423965300.0, 1205607423827200.0, 1205607423689100.5, 1205607423551001.0, 1205607423412901.0, 1205607423274801.5, 1205607423136701.7, 1205607422998602.0, 1205607422860502.5, 1205607422722403.0, 1205607422584303.0, 1205607422446203.5, 1205607422308103.7, 1205607422170004.0, 1205607422031904.5, 1205607421893804.7, 1205607421755705.0, 1205607421617605.5, 1205607421479506.0, 1205607421341406.2, 1205607421203306.5, 1205607421065207.0, 1205607420927107.5, 1205607420789007.7, 1205607420650908.2, 1205607420512808.5, 1205607420374709.0, 1205607420236609.2, 1205607420098509.7, 1205607419960410.0, 1205607419822310.5, 1205607419684210.7, 1205607419546111.5, 1205607419408011.7, 1205607419269912.2, 1205607419131812.5, 1205607418993713.0, 1205607418855613.5, 1205607418717513.7, 1205607418579414.5, 1205607418441314.5, 1205607418303215.0, 1205607418165115.5, 1205607418027016.0, 1205607417888916.5, 1205607417750816.7, 1205607417612717.2, 1205607417474617.5, 1205607417336518.0, 1205607417198418.5, 1205607417060319.0, 1205607416922219.2, 1205607416784119.7, 1205607416646020.2, 1205607416507920.5, 1205607416369821.0, 1205607416231721.5, 1205607416093622.0, 1205607415955522.5, 1205607415817423.0, 1205607415679323.2, 1205607415541223.7, 1205607415403124.2, 1205607415265024.7, 1205607415126925.2, 1205607414988825.5, 1205607414850726.2, 1205607414712626.5, 1205607414574527.0, 1205607414436427.5, 1205607414298328.0, 1205607414160228.5, 1205607414022129.0, 1205607413884029.2, 1205607413745930.0, 1205607413607830.2, 1205607413469730.5, 1205607413331631.2, 1205607413193531.5, 1205607413055432.0, 1205607412917332.5, 1205607412779233.0, 1205607412641133.5, 1205607412503034.0, 1205607412364934.5, 1205607412226835.0, 1205607412088735.5, 1205607411950636.0, 1205607411812536.5, 1205607411674437.0, 1205607411536337.5, 1205607411398238.0, 1205607411260138.5, 1205607411122039.0, 1205607410983939.5, 1205607410845840.0, 1205607410707740.5, 1205607410569640.7, 1205607410431541.2, 1205607410293442.0, 1205607410155342.5, 1205607410017242.7, 1205607409879143.2, 1205607409741044.0, 1205607409602944.5, 1205607409464845.0, 1205607409326745.5, 1205607409188646.0, 1205607409050546.2, 1205607408912447.0, 1205607408774347.5, 1205607408636248.0, 1205607408498148.2, 1205607408360049.0, 1205607408221949.5, 1205607408083850.0, 1205607407945750.5, 1205607407807651.0, 1205607407669551.5, 1205607407531452.0, 1205607407393352.7, 1205607407255253.0, 1205607407117153.5, 1205607406979054.2, 1205607406840954.5, 1205607406702855.2, 1205607406564755.7, 1205607406426656.2, 1205607406288556.7, 1205607406150457.2, 1205607406012358.0, 1205607405874258.2, 1205607405736159.0, 1205607405598059.5, 1205607405459960.0, 1205607405321860.5, 1205607405183761.0, 1205607405045661.5, 1205607404907562.2, 1205607404769462.5]\n"
     ]
    }
   ],
   "source": [
    "l2_penalty_l =0.0\n",
    "multiple_weights_0_penalty=ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, l2_penalty_l, max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's consider high regularization.  Set the `l2_penalty` to `1e11` and run your ridge regression algorithm to learn the weights of your model.  Call your weights:\n",
    "\n",
    "`multiple_weights_high_penalty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent with l2_penalty = 1e+11\n",
      "Iteration = 1\n",
      "Cost function =  7.43305185103e+15\n",
      "Iteration = 2\n",
      "Cost function =  4.0359948934e+15\n",
      "Iteration = 3\n",
      "Cost function =  3.98847313427e+15\n",
      "Iteration = 4\n",
      "Cost function =  3.81829886199e+15\n",
      "Iteration = 5\n",
      "Cost function =  3.9207091733e+15\n",
      "Done with gradient descent at iteration  5\n",
      "Learned weights =  [  3.97457132e-02   1.12051064e+02   3.14741760e+01]\n",
      "[1e+50, 7433051851026171.0, 4035994893402865.0, 3988473134272352.5, 3818298861991971.5]\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.array([0.0,0.0,0.0])\n",
    "step_size = 1e-12\n",
    "max_iterations = 1000\n",
    "l2_penalty_h =1e11\n",
    "multiple_weights_high_penalty=ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, l2_penalty_h, max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RSS on the TEST data for the following three sets of weights:\n",
    "1. The initial weights (all zeros)\n",
    "2. The weights learned with no regularization\n",
    "3. The weights learned with high regularization\n",
    "\n",
    "Which weights perform best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "1.78427328252e+15\n"
     ]
    }
   ],
   "source": [
    "initial_weights = np.array([0.0,0.0,0.0])\n",
    "predictionsm1=predict_output(test_feature_matrix,initial_weights)\n",
    "print predictionsm1\n",
    "errorsm1 = (predictionsm1 -test_output)**2\n",
    "print errorsm1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -0.36692953  243.31658446   22.129868  ]\n",
      "[ 387333.51387442  765141.47472531  438864.75652511 ...,  668924.69324784\n",
      "  602558.60159507  270755.01457084]\n",
      "2.74080549018e+14\n"
     ]
    }
   ],
   "source": [
    "predictionsm2=predict_output(test_feature_matrix,multiple_weights_0_penalty)\n",
    "print multiple_weights_0_penalty\n",
    "print predictionsm2\n",
    "errorsm2 = (predictionsm2 -test_output)**2\n",
    "print errorsm2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.97457132e-02   1.12051064e+02   3.14741760e+01]\n",
      "[ 216257.09493195  397905.41593402  224025.76089282 ...,  361683.64520684\n",
      "  316435.74025656  146395.78481331]\n",
      "6.03592596653e+14\n"
     ]
    }
   ],
   "source": [
    "predictionsm3=predict_output(test_feature_matrix,multiple_weights_high_penalty)\n",
    "print multiple_weights_high_penalty\n",
    "print predictionsm3\n",
    "errorsm3 = (predictionsm3 -test_output)**2\n",
    "print errorsm3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the house price for the 1st house in the test set using the no regularization and high regularization models. (Remember that python starts indexing from 0.) How far is the prediction from the actual price?  Which weights perform best for the 1st house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387333.513874\n"
     ]
    }
   ],
   "source": [
    "pre_l=predict_output(test_feature_matrix[0],multiple_weights_0_penalty)\n",
    "print pre_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216257.094932\n"
     ]
    }
   ],
   "source": [
    "pre_h=predict_output(test_feature_matrix[0],multiple_weights_high_penalty)\n",
    "print pre_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310000.0\n",
      "[ 310000.  650000.  233000. ...,  610685.  400000.  402101.]\n"
     ]
    }
   ],
   "source": [
    "print test_data['price'][0]\n",
    "print test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What is the value of the coefficient for `sqft_living` that you learned with no regularization, rounded to 1 decimal place?  What about the one with high regularization?\n",
    "2. What are the RSS on the test data for each of the set of weights above (initial, no regularization, high regularization)? \n",
    "3. We make prediction for the first house in the test set using two sets of weights (no regularization vs high regularization). Which weights make better prediction <u>for that particular house</u>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77333.513874417404"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_l-310000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93742.905068"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "310000-216257.094932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
